---
title: "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)"
author:
  - name: Алексей Якиманский
    id: avytheone
    email: yakimanskiyav@yandex.ru
    affiliation: Netology, DSU-73
abstract: >
    В данном исследовании проводится комплексный анализ данных о сердечно-сосудистых заболеваниях с целью выявления ключевых факторов риска и построения предиктивных моделей. Анализ включает исследовательский анализ данных, разработку и сравнение моделей машинного обучения для прогнозирования наличия сердечно-сосудистых заболеваний.
copyright: 
  holder: Алексей Якиманский
  year: 2026
  license: "CC BY"
pdf-engine: typst
mainfont: "Times New Roman"
lightbox: true
format:
  html:
    page-layout: full
---

# Введение

Сердечно-сосудистые заболевания являются основной причиной смертности во многих странах мира. Раннее выявление факторов риска и своевременная профилактика играют ключевую роль в снижении заболеваемости и смертности.

## Цель исследования

Основной целью данного исследования является анализ факторов риска сердечно-сосудистых заболеваний на основе данных медицинских обследований и построение предиктивных моделей для оценки вероятности наличия заболевания.

## Задачи исследования

1. Провести исследовательский анализ данных для выявления ключевых закономерностей
2. Выполнить очистку и предобработку данных
3. Построить и оценить предиктивные модели
4. Сформулировать практические рекомендации для заинтересованных лиц

## Основные стейкхолдеры

### 1. Медицинская лаборатория

**Приоритеты:**

- Повышение точности диагностики сердечно-сосудистых заболеваний
- Оптимизация скрининговых программ
- Снижение затрат на обработку данных
- Улучшение качества предоставляемых услуг

**Задачи:**

- Внедрение предиктивных моделей в рутинную практику
- Обучение персонала работе с ML-инструментами
- Интеграция моделей в существующие лабораторные системы
- Мониторинг эффективности внедренных решений

### 2. Врачи-кардиологи и терапевты

**Приоритеты:**

- Получение точных инструментов для оценки риска пациентов
- Сокращение времени на принятие клинических решений
- Повышение качества лечения и профилактики
- Снижение пропускной способности высокорисковых пациентов

**Задачи:**

- Использование предиктивных моделей в клинической практике
- Интерпретация результатов ML-моделей для пациентов
- Адапация рекомендаций под индивидуальные особенности пациентов
- Обеспечение этического использования алгоритмов

### 3. Пациенты

**Приоритеты:**

- Своевременное выявление рисков сердечно-сосудистых заболеваний
- Получение персонализированных рекомендаций
- Повышение качества жизни и здоровья
- Снижение тревожности относительно состояния здоровья

**Задачи:**

- Прохождение регулярных обследований
- Следование рекомендациям по изменению образа жизни
- Активное участие в программах мониторинга здоровья
- Соблюдение предписанного лечения

### 4. Система здравоохранения

**Приоритеты:**

- Снижение общей заболеваемости и смертности от ССЗ
- Оптимизация распределения медицинских ресурсов
- Повышение эффективности профилактических программ
- Снижение экономических затрат на лечение ССЗ

**Задачи:**

- Разработка и внедрение национальных скрининговых программ
- Создание реестров пациентов с высоким риском
- Обеспечение доступности качественной медицинской помощи
- Мониторинг популяционных показателей здоровья

### 5. Страховые компании

**Приоритеты:**

- Снижение выплат по дорогостоящим случаям лечения ССЗ
- Оптимизация тарифов страховых продуктов
- Повышение удержания клиентов через профилактические программы
- Точный расчет актуарных рисков

**Задачи:**

- Разработка программ превентивной медицины
- Интеграция моделей оценки рисков в андеррайтинг
- Создание стимулов для здорового образа жизни клиентов
- Мониторинг медицинских расходов клиентов

### 6. Исследователи и академическое сообщество

**Приоритеты:**

- Получение новых научных знаний о факторах риска ССЗ
- Валидация методологий машинного обучения в медицине
- Публикация результатов в рецензируемых журналах
- Развитие междисциплинарного сотрудничества

**Задачи:**

- Проведение дополнительных исследований на расширенных данных
- Валидация моделей на независимых выборках
- Разработка новых методологий анализа
- Подготовка научных публикаций и презентаций

### 7. Разработчики медицинских технологий

**Приоритеты:**

- Создание коммерчески жизнеспособных продуктов
- Обеспечение соответствия регуляторным требованиям
- Масштабирование решений для широкого использования
- Поддержание конкурентоспособности на рынке

**Задачи:**

- Разработка пользовательских интерфейсов для клиницистов
- Интеграция с существующими медицинскими системами (HIS/EMR)
- Обеспечение безопасности и конфиденциальности данных
- Проведение клинических испытаний и сертификация

## Ключевые метрики успеха для стейкхолдеров

### Медицинская лаборатория:
- Снижение времени обработки анализов
- Повышение точности прогнозирования 
- Увеличение количества обслуживаемых пациентов

### Врачи:
- Сокращение времени на принятие решений 
- Повышение выявляемости заболеваний на ранних стадиях 
- Удовлетворенность пациентов

### Пациенты:
- Повышение приверженности лечению 
- Снижение прогрессирования заболеваний 
- Улучшение качества жизни 

### Система здравоохранения:
- Снижение госпитализаций по поводу ССЗ 
- Экономическая эффективность 
- Покрытие скринингом большей части целевой популяции

# Обзор данных

В исследовании используется датасет Cardiovascular Disease Dataset, содержащий информацию о 70 000 пациентах. Данные предоставлены медицинской лабораторией и включают 11 признаков и целевую переменную наличия сердечно-сосудистого заболевания.

## Описание признаков

- **age** - возраст в днях
- **gender** - пол (1 - женщина, 2 - мужчина)
- **height** - рост в см
- **weight** - вес в кг
- **ap_hi** - систолическое артериальное давление
- **ap_lo** - диастолическое артериальное давление
- **cholesterol** - уровень холестерина (1: нормальный, 2: выше нормы, 3: высокий)
- **gluc** - уровень глюкозы (1: нормальный, 2: выше нормы, 3: высокий)
- **smoke** - курение (0: нет, 1: да)
- **alco** - употребление алкоголя (0: нет, 1: да)
- **active** - физическая активность (0: нет, 1: да)
- **cardio** - наличие сердечно-сосудистого заболевания (0: нет, 1: да)

# Методология

## Подходы к анализу

Исследование будет проводиться в несколько этапов:

1. **Исследовательский анализ данных (EDA)**: анализ распределений, выявление выбросов, изучение взаимосвязей
2. **Предобработка данных**: очистка, нормализация, создание новых признаков
3. **Моделирование**: построение и сравнение моделей машинного обучения
4. **Интерпретация результатов**: анализ важности признаков и формулирование выводов

## Инструменты анализа

- **Python 3.12+** с научными библиотеками pandas, numpy, matplotlib, seaborn
- **scikit-learn** для построения моделей машинного обучения
- **Quarto** для генерации отчета

# Результаты EDA

## Настройка окружения

Для начала импортируем необходимые библиотеки и настроим параметры визуализации.

```{python}
#| label: imports

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from pathlib import Path
from great_tables import GT

```

Настроим параметры отображения в ноутбуке

```{python}
#| label: setup
#| fig-cap: "Настройка системы"

np.random.seed(31337)

warnings.filterwarnings('ignore')

# Настройки для визуализаций
plt.style.use('seaborn-v0_8-whitegrid')

# Монохромная палитра с красными акцентами
colors = ['#808080', '#606060', '#404040', '#FF6B6B', '#CC5555']
sns.set_palette(colors)

plt.rcParams['font.size'] = 11
plt.rcParams['figure.titlesize'] = 14
plt.rcParams['axes.titlesize'] = 12
plt.rcParams['axes.labelsize'] = 11
```

## Загрузка данных

Загрузим набор данных и выведем основную информацию о его размере.

```{python}
#| label: load-data
#| fig-cap: "Загрузка данных"

DF_CSV_PATH = 'data/cardio_train.csv'
df = pd.read_csv(DF_CSV_PATH, sep=';')
```

## Предварительный просмотр

Ознакомимся со структурой данных предоставленного датасета.

```{python}
print(f"Размер датасета: {df.shape}")
```

```{python}
#| label: view-head
#| tbl-cap: "Первые 5 строк датасета"

GT(df.head())
```

## Типы данных

Проверим типы данных каждого признака, чтобы убедиться в их корректности.

```{python}
#| label: check-types
#| tbl-cap: "Типы данных в датасете"

types_df = df.dtypes.reset_index()
types_df.columns = ["Признак", "Тип данных"]
GT(types_df)
```

## Описательная статистика

Рассмотрим основные статистические характеристики числовых признаков.

```{python}
#| label: describe-stats
#| tbl-cap: "Описательная статистика числовых признаков"

stats_df = df.describe().reset_index()
GT(stats_df)
```

## Проверка на пропуски

Важным этапом является проверка данных на наличие пропущенных значений.

```{python}
#| label: check-missing
#| tbl-cap: "Анализ пропущенных значений"

# Проверка пропусков
missing_values = df.isnull().sum().reset_index()
missing_values.columns = ["Признак", "Количество пропусков"]

if missing_values["Количество пропусков"].sum() == 0:
    print("Пропусков не обнаружено")
else:
    GT(missing_values[missing_values["Количество пропусков"] > 0])
```

## Проверка дубликатов

Проверим наличие полных дубликатов записей, которые могут исказить результаты анализа, и удалим их при наличии.

```{python}
#| label: check-duplicates
#| fig-cap: "Обработка дубликатов"

# Проверка дубликатов
duplicates = df.duplicated().sum()
print(f"Количество полных дубликатов: {duplicates}")

# Удаление дубликатов если есть
if duplicates > 0:
    df = df.drop_duplicates()
    print(f"После удаления дубликатов размер: {df.shape}")
```

## Анализ категориальных признаков (структура)

Посмотрим на уникальные значения в категориальных переменных для понимания их структуры.

```{python}
#| label: check-unique
#| tbl-cap: "Уникальные значения категориальных признаков"

categorical_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']
unique_data = []

for col in categorical_cols:
    unique_vals = sorted(df[col].unique())
    unique_data.append({"Признак": col, "Уникальные значения": str(unique_vals)})

GT(pd.DataFrame(unique_data))
```

## Распределение целевой переменной

Проанализируем сбалансированность классов целевой переменной `cardio`. Это важно для выбора метрик оценки моделей.

```{python}
#| label: target-distribution-plot
#| fig-cap: "График распределения наличия сердечно-сосудистых заболеваний"
#| fig-width: 8
#| fig-height: 6

plt.figure(figsize=(8, 6))
ax = sns.countplot(data=df, x='cardio', palette=['#808080', '#FF6B6B'])
plt.title('Распределение наличия сердечно-сосудистых заболеваний', fontsize=14, pad=20)
plt.xlabel('Наличие заболевания (0 - нет, 1 - да)', fontsize=12)
plt.ylabel('Количество пациентов', fontsize=12)

# Добавление процентов
total = len(df)
for p in ax.patches:
    percentage = f'{100 * p.get_height() / total:.1f}%'
    ax.annotate(percentage, (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', fontsize=11)

plt.tight_layout()
plt.show()
```

Детальная статистика распределения целевой переменной:

```{python}
#| label: target-stats
#| tbl-cap: "Статистика распределения целевой переменной"

target_stats = df['cardio'].value_counts().reset_index()
target_stats.columns = ['Cardio', 'Count']
target_stats['Percentage'] = (target_stats['Count'] / total * 100).round(1).astype(str) + '%'
GT(target_stats)
```

## Распределения числовых признаков

Для удобства анализа преобразуем возраст из дней в годы.

```{python}
#| label: calc-age
df['age_years'] = df['age'] / 365.25
```

### Возраст

Рассмотрим распределение возраста пациентов.

```{python}
#| label: dist-age
#| fig-cap: "Гистограмма распределения возраста"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='age_years', bins=30, color='#808080', alpha=0.7)
plt.title('Распределение возраста (годы)', fontsize=14)
plt.xlabel('Возраст, лет')
plt.ylabel('Частота')
plt.grid(True, alpha=0.3)
plt.show()
```

### Рост

Анализ распределения роста пациентов.

```{python}
#| label: dist-height
#| fig-cap: "Гистограмма распределения роста"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='height', bins=30, color='#808080', alpha=0.7)
plt.title('Распределение роста', fontsize=14)
plt.xlabel('Рост, см')
plt.ylabel('Частота')
plt.grid(True, alpha=0.3)
plt.show()
```

### Вес

Анализ распределения веса пациентов.

```{python}
#| label: dist-weight
#| fig-cap: "Гистограмма распределения веса"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='weight', bins=30, color='#808080', alpha=0.7)
plt.title('Распределение веса', fontsize=14)
plt.xlabel('Вес, кг')
plt.ylabel('Частота')
plt.grid(True, alpha=0.3)
plt.show()
```

### Систолическое давление

Распределение верхнего (систолического) артериального давления.

```{python}
#| label: dist-ap-hi
#| fig-cap: "Гистограмма систолического давления"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='ap_hi', bins=30, color='#808080', alpha=0.7)
plt.title('Систолическое артериальное давление', fontsize=14)
plt.xlabel('Давление, мм рт.ст.')
plt.ylabel('Частота')
plt.grid(True, alpha=0.3)
plt.show()
```

### Диастолическое давление

Распределение нижнего (диастолического) артериального давления.

```{python}
#| label: dist-ap-lo
#| fig-cap: "Гистограмма диастолического давления"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='ap_lo', bins=30, color='#808080', alpha=0.7)
plt.title('Диастолическое артериальное давление', fontsize=14)
plt.xlabel('Давление, мм рт.ст.')
plt.ylabel('Частота')
plt.grid(True, alpha=0.3)
plt.show()
```

## Распределения категориальных признаков

Проанализируем категориальные факторы риска.

### Пол

Соотношение мужчин и женщин в выборке.

```{python}
#| label: dist-gender
#| fig-cap: "Столбчатая диаграмма распределения по полу"
#| fig-width: 8
#| fig-height: 6

gender_counts = df['gender'].value_counts()
plt.figure(figsize=(8, 6))
sns.barplot(x=['Женщины', 'Мужчины'], y=gender_counts.values, 
            palette=['#808080', '#FF6B6B'])
plt.title('Распределение по полу', fontsize=14)
plt.ylabel('Количество')
plt.grid(axis='y', alpha=0.3)
plt.show()
```

### Холестерин

Уровни холестерина среди пациентов.

```{python}
#| label: dist-cholesterol
#| fig-cap: "Столбчатая диаграмма уровней холестерина"
#| fig-width: 8
#| fig-height: 6

cholesterol_counts = df['cholesterol'].value_counts().sort_index()
plt.figure(figsize=(8, 6))
plt.bar(['Норма', 'Выше нормы', 'Высокий'], cholesterol_counts.values, 
        color=['#808080', '#606060', '#FF6B6B'])
plt.title('Уровень холестерина', fontsize=14)
plt.ylabel('Количество')
plt.grid(axis='y', alpha=0.3)
plt.show()
```

### Глюкоза

Уровни глюкозы среди пациентов.

```{python}
#| label: dist-gluc
#| fig-cap: "Столбчатая диаграмма уровней глюкозы"
#| fig-width: 8
#| fig-height: 6

gluc_counts = df['gluc'].value_counts().sort_index()
plt.figure(figsize=(8, 6))
plt.bar(['Норма', 'Выше нормы', 'Высокий'], gluc_counts.values, 
        color=['#808080', '#606060', '#FF6B6B'])
plt.title('Уровень глюкозы', fontsize=14)
plt.ylabel('Количество')
plt.grid(axis='y', alpha=0.3)
plt.show()
```

### Курение

Доля курящих пациентов.

```{python}
#| label: dist-smoke
#| fig-cap: "Столбчатая диаграмма статуса курения"
#| fig-width: 8
#| fig-height: 6

smoke_counts = df['smoke'].value_counts()
plt.figure(figsize=(8, 6))
sns.barplot(x=['Не курят', 'Курят'], y=smoke_counts.values, 
            palette=['#808080', '#FF6B6B'])
plt.title('Курение', fontsize=14)
plt.ylabel('Количество')
plt.grid(axis='y', alpha=0.3)
plt.show()
```

### Алкоголь

Доля пациентов, употребляющих алкоголь.

```{python}
#| label: dist-alco
#| fig-cap: "Столбчатая диаграмма употребления алкоголя"
#| fig-width: 8
#| fig-height: 6

alco_counts = df['alco'].value_counts()
plt.figure(figsize=(8, 6))
sns.barplot(x=['Не употребляют', 'Употребляют'], y=alco_counts.values, 
            palette=['#808080', '#FF6B6B'])
plt.title('Употребление алкоголя', fontsize=14)
plt.ylabel('Количество')
plt.grid(axis='y', alpha=0.3)
plt.show()
```

### Физическая активность

Уровень физической активности пациентов.

```{python}
#| label: dist-active
#| fig-cap: "Столбчатая диаграмма физической активности"
#| fig-width: 8
#| fig-height: 6

active_counts = df['active'].value_counts()
plt.figure(figsize=(8, 6))
sns.barplot(x=['Неактивны', 'Активны'], y=active_counts.values, 
            palette=['#808080', '#FF6B6B'])
plt.title('Физическая активность', fontsize=14)
plt.ylabel('Количество')
plt.grid(axis='y', alpha=0.3)
plt.show()
```

## Корреляционный анализ

Изучим линейные взаимосвязи между признаками, построив матрицу корреляций.

```{python}
#| label: correlation-heatmap
#| fig-cap: "Тепловая карта корреляционной матрицы"
#| fig-width: 12
#| fig-height: 10

# Подготовка данных для корреляции
df_corr = df.drop(['id'], axis=1)

# Расчет корреляционной матрицы
correlation_matrix = df_corr.corr()

# Создание маски для верхней треугольной части
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,
            square=True, fmt='.2f', cbar_kws={"shrink": .8})
plt.title('Корреляционная матрица признаков', fontsize=16, pad=20)
plt.tight_layout()
plt.show()
```

Выделим наиболее сильные корреляции для детального рассмотрения.

```{python}
#| label: strong-correlations
#| tbl-cap: "Сильные корреляции (|r| > 0.3)"

strong_correlations = []
for i in range(len(correlation_matrix.columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > 0.3:
            strong_correlations.append({
                'Пара признаков': f"{correlation_matrix.columns[i]} - {correlation_matrix.columns[j]}",
                'Коэффициент корреляции': correlation_matrix.iloc[i, j]
            })

GT(pd.DataFrame(strong_correlations))
```

## Анализ выбросов

Используем диаграммы размаха (boxplot) для выявления аномальных значений в числовых признаках.

### Выбросы: Возраст

```{python}
#| label: box-age
#| fig-cap: "Box plot для возраста"
#| fig-width: 8
#| fig-height: 4

plt.figure(figsize=(8, 4))
sns.boxplot(data=df, x='age_years', color='#808080')
plt.title('Box Plot: Возраст', fontsize=14)
plt.xlabel('Лет')
plt.show()
```

### Выбросы: Рост

```{python}
#| label: box-height
#| fig-cap: "Box plot для роста"
#| fig-width: 8
#| fig-height: 4

plt.figure(figsize=(8, 4))
sns.boxplot(data=df, x='height', color='#808080')
plt.title('Box Plot: Рост', fontsize=14)
plt.xlabel('см')
plt.show()
```

### Выбросы: Вес

```{python}
#| label: box-weight
#| fig-cap: "Box plot для веса"
#| fig-width: 8
#| fig-height: 4

plt.figure(figsize=(8, 4))
sns.boxplot(data=df, x='weight', color='#808080')
plt.title('Box Plot: Вес', fontsize=14)
plt.xlabel('кг')
plt.show()
```

### Выбросы: Систолическое давление

```{python}
#| label: box-ap-hi
#| fig-cap: "Box plot для систолического давления"
#| fig-width: 8
#| fig-height: 4

plt.figure(figsize=(8, 4))
sns.boxplot(data=df, x='ap_hi', color='#808080')
plt.title('Box Plot: Систолическое давление', fontsize=14)
plt.xlabel('мм рт.ст.')
plt.show()
```

### Выбросы: Диастолическое давление

```{python}
#| label: box-ap-lo
#| fig-cap: "Box plot для диастолического давления"
#| fig-width: 8
#| fig-height: 4

plt.figure(figsize=(8, 4))
sns.boxplot(data=df, x='ap_lo', color='#808080')
plt.title('Box Plot: Диастолическое давление', fontsize=14)
plt.xlabel('мм рт.ст.')
plt.show()
```

Количественная оценка выбросов по методу межквартильного размаха (IQR).

```{python}
#| label: outliers-stats
#| tbl-cap: "Статистика по выбросам"

numeric_features = ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo']
outliers_data = []

for feature in numeric_features:
    Q1 = df[feature].quantile(0.25)
    Q3 = df[feature].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers_count = len(df[(df[feature] < lower_bound) | (df[feature] > upper_bound)])
    outliers_data.append({
        'Признак': feature,
        'Количество выбросов': outliers_count,
        'Процент': f"{outliers_count/len(df)*100:.1f}%"
    })

GT(pd.DataFrame(outliers_data))
```

## Очистка данных

На основе EDA проведем очистку данных от аномальных и нереалистичных значений.

### Инициализация

Создадим копию датафрейма для очистки.

```{python}
#| label: clean-init
df_clean = df.copy()
print(f"Исходный размер датасета: {df_clean.shape}")
```

### Очистка артериального давления

Фильтрация нереалистичных значений давления. Используем следующие критерии:
- Систолическое: 70-250 мм рт.ст.
- Диастолическое: 40-150 мм рт.ст.
- Систолическое должно быть выше диастолического.

```{python}
#| label: clean-pressure
#| fig-cap: "Очистка давления"

before_pressure = len(df_clean)
df_clean = df_clean[
    (df_clean['ap_hi'] >= 70) & (df_clean['ap_hi'] <= 250) &
    (df_clean['ap_lo'] >= 40) & (df_clean['ap_lo'] <= 150) &
    (df_clean['ap_hi'] > df_clean['ap_lo'])
]
after_pressure = len(df_clean)
print(f"Удалено записей с нереалистичным давлением: {before_pressure - after_pressure}")
```

### Очистка антропометрических данных

Фильтрация по росту и весу:
- Рост: 100-220 см
- Вес: 30-250 кг

```{python}
#| label: clean-anthro
#| fig-cap: "Очистка роста и веса"

before_anthro = len(df_clean)
df_clean = df_clean[
    (df_clean['height'] >= 100) & (df_clean['height'] <= 220) &
    (df_clean['weight'] >= 30) & (df_clean['weight'] <= 250)
]
after_anthro = len(df_clean)
print(f"Удалено записей с нереалистичным ростом/весом: {before_anthro - after_anthro}")
```

### Очистка возраста

Оставляем пациентов от 18 до 100 лет.

```{python}
#| label: clean-age
#| fig-cap: "Очистка возраста"

before_age = len(df_clean)
df_clean = df_clean[
    (df_clean['age_years'] >= 18) & (df_clean['age_years'] <= 100)
]
after_age = len(df_clean)
print(f"Удалено записей с нереалистичным возрастом: {before_age - after_age}")
```

### Расчет BMI

Рассчитаем индекс массы тела (BMI) для дальнейшего анализа.

```{python}
#| label: calc-bmi
df_clean['bmi'] = df_clean['weight'] / (df_clean['height'] / 100) ** 2
print(f"Итоговый размер после очистки: {df_clean.shape}")
```

Статистика очищенного датасета:

```{python}
#| label: clean-stats
#| tbl-cap: "Статистика после очистки"

clean_stats = df_clean[['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'bmi']].describe().reset_index()
GT(clean_stats)
```

## Анализ BMI и категоризация

### Распределение BMI

Посмотрим на распределение индекса массы тела в очищенной выборке.

```{python}
#| label: dist-bmi
#| fig-cap: "Гистограмма распределения BMI"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
sns.histplot(data=df_clean, x='bmi', bins=30, color='#808080', alpha=0.7)
plt.axvline(x=18.5, color='blue', linestyle='--', alpha=0.7, label='Недостаточный вес')
plt.axvline(x=25, color='green', linestyle='--', alpha=0.7, label='Норма')
plt.axvline(x=30, color='orange', linestyle='--', alpha=0.7, label='Избыточный вес')
plt.axvline(x=35, color='red', linestyle='--', alpha=0.7, label='Ожирение')
plt.title('Распределение BMI', fontsize=14)
plt.xlabel('BMI')
plt.ylabel('Частота')
plt.legend()
plt.show()
```

### Категории BMI

Разделим пациентов на группы согласно классификации ВОЗ.

```{python}
#| label: bmi-categories-calc
def categorize_bmi(bmi):
    if bmi < 18.5:
        return 'Недостаточный вес'
    elif bmi < 25:
        return 'Норма'
    elif bmi < 30:
        return 'Избыточный вес'
    elif bmi < 35:
        return 'Ожирение I степени'
    else:
        return 'Ожирение II+ степени'

df_clean['bmi_category'] = df_clean['bmi'].apply(categorize_bmi)
bmi_counts = df_clean['bmi_category'].value_counts()
```

Визуализация распределения по категориям:

```{python}
#| label: bmi-pie
#| fig-cap: "Столбчатая диаграмма категорий BMI"
#| fig-width: 10
#| fig-height: 6

colors_bmi = ['#404040', '#606060', '#808080', '#FF6B6B', '#CC5555']
plt.figure(figsize=(10, 6))
sns.barplot(x=bmi_counts.index, y=bmi_counts.values, palette=colors_bmi)
plt.title('Категории BMI', fontsize=14)
plt.ylabel('Количество')
plt.grid(axis='y', alpha=0.3)
plt.show()
```

Детальная статистика по категориям BMI:

```{python}
#| label: bmi-table
#| tbl-cap: "Статистика по категориям BMI"

bmi_table = bmi_counts.reset_index()
bmi_table.columns = ['Категория', 'Количество']
bmi_table['Доля'] = (bmi_table['Количество'] / len(df_clean) * 100).round(1).astype(str) + '%'
GT(bmi_table)
```

# Построение моделей

## Подготовка данных для моделирования

Импорт необходимых библиотек для машинного обучения.

```{python}
#| label: ml-imports
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, roc_curve, 
                           confusion_matrix, classification_report)
```

Разделение данных на матрицу признаков (X) и целевой вектор (y).

```{python}
#| label: split-xy
# Удаляем нерелевантные признаки и подготовляем X, y
X = df_clean.drop(['id', 'age', 'cardio', 'bmi_category'], axis=1)
y = df_clean['cardio']

print(f"Признаки для моделирования: {list(X.columns)}")
print(f"Размер признакового пространства: {X.shape}")
```

Разделение на обучающую и тестовую выборки.

```{python}
#| label: train-test-split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Размер обучающей выборки: {X_train.shape}")
print(f"Размер тестовой выборки: {X_test.shape}")
```

Стандартизация числовых признаков для улучшения работы линейных моделей.

```{python}
#| label: scaling
numeric_features = ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'bmi']
scaler = StandardScaler()

X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()

X_train_scaled[numeric_features] = scaler.fit_transform(X_train[numeric_features])
X_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])

print("Числовые признаки стандартизированы")
```

## Обучение моделей

Настройка кросс-валидации.

```{python}
#| label: cv-setup
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

### Logistic Regression

Обучение логистической регрессии как базовой модели.

```{python}
#| label: train-lr
print("Обучение Logistic Regression...")
lr_model = LogisticRegression(random_state=42, max_iter=1000)

# Cross-validation
lr_cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=cv, scoring='roc_auc')
print(f"Logistic Regression CV AUC: {lr_cv_scores.mean():.4f} ± {lr_cv_scores.std():.4f}")

# Обучение на полных данных
lr_model.fit(X_train_scaled, y_train)
```

### Random Forest

Обучение случайного леса для выявления нелинейных зависимостей.

```{python}
#| label: train-rf
print("Обучение Random Forest...")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)

# Cross-validation
rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='roc_auc')
print(f"Random Forest CV AUC: {rf_cv_scores.mean():.4f} ± {rf_cv_scores.std():.4f}")

# Обучение на полных данных
rf_model.fit(X_train, y_train)
```

## Оценка качества моделей

Определим функцию для расчета метрик.

```{python}
#| label: eval-func
def evaluate_model(model, X_test_data, y_test_data, model_name):
    """Функция для оценки модели"""
    # Предсказания
    y_pred = model.predict(X_test_data)
    y_pred_proba = model.predict_proba(X_test_data)[:, 1]
    
    # Метрики
    cm = confusion_matrix(y_test_data, y_pred)
    tn, fp, fn, tp = cm.ravel()
    specificity = tn / (tn + fp)
    
    metrics = {
        'Accuracy': accuracy_score(y_test_data, y_pred),
        'Precision': precision_score(y_test_data, y_pred),
        'Recall': recall_score(y_test_data, y_pred),
        'F1-Score': f1_score(y_test_data, y_pred),
        'ROC-AUC': roc_auc_score(y_test_data, y_pred_proba),
        'Specificity': specificity
    }
    
    return metrics, y_pred, y_pred_proba
```

Получение метрик для обеих моделей.

```{python}
#| label: calc-metrics
lr_metrics, lr_pred, lr_pred_proba = evaluate_model(
    lr_model, X_test_scaled, y_test, "Logistic Regression"
)

rf_metrics, rf_pred, rf_pred_proba = evaluate_model(
    rf_model, X_test, y_test, "Random Forest"
)
```

### Сравнение метрик (График)

Визуальное сравнение основных метрик моделей.

```{python}
#| label: compare-plot
#| fig-cap: "Сравнение метрик качества моделей"
#| fig-width: 10
#| fig-height: 6

metrics_comparison = pd.DataFrame({
    'Logistic Regression': lr_metrics,
    'Random Forest': rf_metrics
}).T

plt.figure(figsize=(10, 6))
metrics_comparison.plot(kind='bar', color=['#808080', '#FF6B6B', '#606060', '#404040', '#CC5555', '#909090'])
plt.title('Сравнение метрик качества моделей', fontsize=14, pad=20)
plt.xlabel('Модель', fontsize=12)
plt.ylabel('Значение метрики', fontsize=12)
plt.legend(title='Метрики', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()
```

### Сравнение метрик (Таблица)

Детальная таблица со значениями метрик.

```{python}
#| label: compare-table
#| tbl-cap: "Таблица метрик качества"

GT(metrics_comparison.reset_index().rename(columns={'index': 'Модель'}).round(4))
```

## ROC-кривые

Сравнение способности моделей разделять классы с помощью ROC-анализа.

```{python}
#| label: roc-curve-plot
#| fig-cap: "ROC-кривые моделей"
#| fig-width: 10
#| fig-height: 8

plt.figure(figsize=(10, 8))

# Logistic Regression
fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_pred_proba)
auc_lr = roc_auc_score(y_test, lr_pred_proba)
plt.plot(fpr_lr, tpr_lr, color='#808080', lw=2, 
         label=f'Logistic Regression (AUC = {auc_lr:.3f})')

# Random Forest
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_pred_proba)
auc_rf = roc_auc_score(y_test, rf_pred_proba)
plt.plot(fpr_rf, tpr_rf, color='#FF6B6B', lw=2, 
         label=f'Random Forest (AUC = {auc_rf:.3f})')

# Диагональ
plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--', alpha=0.7)

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC-кривые для сравнения моделей', fontsize=14, pad=20)
plt.legend(loc="lower right", fontsize=11)
plt.grid(True, alpha=0.3)
plt.show()
```

## Матрицы ошибок

Анализ структуры ошибок для каждой модели.

### Logistic Regression

```{python}
#| label: cm-lr
#| fig-cap: "Матрица ошибок Logistic Regression"
#| fig-width: 6
#| fig-height: 5

plt.figure(figsize=(6, 5))
cm_lr = confusion_matrix(y_test, lr_pred)
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', 
           xticklabels=['Нет заболевания', 'Есть заболевание'],
           yticklabels=['Нет заболевания', 'Есть заболевание'])
plt.title('Logistic Regression: Матрица ошибок', fontsize=12)
plt.xlabel('Предсказано')
plt.ylabel('Фактически')
plt.tight_layout()
plt.show()
```

### Random Forest

```{python}
#| label: cm-rf
#| fig-cap: "Матрица ошибок Random Forest"
#| fig-width: 6
#| fig-height: 5

plt.figure(figsize=(6, 5))
cm_rf = confusion_matrix(y_test, rf_pred)
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',
           xticklabels=['Нет заболевания', 'Есть заболевание'],
           yticklabels=['Нет заболевания', 'Есть заболевание'])
plt.title('Random Forest: Матрица ошибок', fontsize=12)
plt.xlabel('Предсказано')
plt.ylabel('Фактически')
plt.tight_layout()
plt.show()
```

## Важность признаков

Анализ того, какие признаки оказали наибольшее влияние на предсказания модели Random Forest.

```{python}
#| label: feat-imp-plot
#| fig-cap: "График важности признаков (Random Forest)"
#| fig-width: 10
#| fig-height: 8

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 8))
sns.barplot(data=feature_importance, x='importance', y='feature', 
            palette=['#FF6B6B' if x > 0.1 else '#808080' for x in feature_importance['importance']])
plt.title('Важность признаков (Random Forest)', fontsize=14, pad=20)
plt.xlabel('Важность', fontsize=12)
plt.ylabel('Признак', fontsize=12)
plt.tight_layout()
plt.show()
```

Топ-10 наиболее важных признаков для Random Forest:

```{python}
#| label: feat-imp-table
#| tbl-cap: "Топ-10 признаков (Random Forest)"

GT(feature_importance.head(10))
```

Коэффициенты логистической регрессии для интерпретации влияния признаков.

```{python}
#| label: lr-coef-table
#| tbl-cap: "Топ-10 коэффициентов Logistic Regression"

lr_coefficients = pd.DataFrame({
    'feature': X.columns,
    'coefficient': lr_model.coef_[0],
    'abs_coefficient': np.abs(lr_model.coef_[0])
}).sort_values('abs_coefficient', ascending=False)

GT(lr_coefficients.head(10)[['feature', 'coefficient']])
```

## Детальное сравнение метрик

Построим отдельные графики для каждой метрики.

```{python}
#| label: detailed-comparison-data
metrics_list = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Specificity']
models = ['Logistic Regression', 'Random Forest']
colors = ['#808080', '#FF6B6B']
```

### Accuracy

```{python}
#| label: comp-accuracy
#| fig-cap: "Сравнение Accuracy"
#| fig-width: 6
#| fig-height: 4

val_acc = [lr_metrics['Accuracy'], rf_metrics['Accuracy']]
plt.figure(figsize=(6, 4))
bars = plt.bar(models, val_acc, color=colors)
plt.title('Accuracy')
plt.ylim(0, 1)
for bar, value in zip(bars, val_acc):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')
plt.show()
```

### Precision

```{python}
#| label: comp-precision
#| fig-cap: "Сравнение Precision"
#| fig-width: 6
#| fig-height: 4

val_prec = [lr_metrics['Precision'], rf_metrics['Precision']]
plt.figure(figsize=(6, 4))
bars = plt.bar(models, val_prec, color=colors)
plt.title('Precision')
plt.ylim(0, 1)
for bar, value in zip(bars, val_prec):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')
plt.show()
```

### Recall

```{python}
#| label: comp-recall
#| fig-cap: "Сравнение Recall"
#| fig-width: 6
#| fig-height: 4

val_rec = [lr_metrics['Recall'], rf_metrics['Recall']]
plt.figure(figsize=(6, 4))
bars = plt.bar(models, val_rec, color=colors)
plt.title('Recall')
plt.ylim(0, 1)
for bar, value in zip(bars, val_rec):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')
plt.show()
```

### F1-Score

```{python}
#| label: comp-f1
#| fig-cap: "Сравнение F1-Score"
#| fig-width: 6
#| fig-height: 4

val_f1 = [lr_metrics['F1-Score'], rf_metrics['F1-Score']]
plt.figure(figsize=(6, 4))
bars = plt.bar(models, val_f1, color=colors)
plt.title('F1-Score')
plt.ylim(0, 1)
for bar, value in zip(bars, val_f1):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')
plt.show()
```

### ROC-AUC

```{python}
#| label: comp-auc
#| fig-cap: "Сравнение ROC-AUC"
#| fig-width: 6
#| fig-height: 4

val_auc = [lr_metrics['ROC-AUC'], rf_metrics['ROC-AUC']]
plt.figure(figsize=(6, 4))
bars = plt.bar(models, val_auc, color=colors)
plt.title('ROC-AUC')
plt.ylim(0, 1)
for bar, value in zip(bars, val_auc):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')
plt.show()
```

### Specificity

```{python}
#| label: comp-spec
#| fig-cap: "Сравнение Specificity"
#| fig-width: 6
#| fig-height: 4

val_spec = [lr_metrics['Specificity'], rf_metrics['Specificity']]
plt.figure(figsize=(6, 4))
bars = plt.bar(models, val_spec, color=colors)
plt.title('Specificity')
plt.ylim(0, 1)
for bar, value in zip(bars, val_spec):
    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')
plt.show()
```

## Анализ пороговых значений

Исследуем, как меняются метрики при изменении порога классификации.

```{python}
#| label: thresholds-calc
thresholds = np.arange(0.3, 0.8, 0.05)

def calculate_metrics_at_threshold(y_true, y_proba, threshold):
    y_pred = (y_proba >= threshold).astype(int)
    return {
        'threshold': threshold,
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred),
        'recall': recall_score(y_true, y_pred),
        'f1': f1_score(y_true, y_pred)
    }

threshold_metrics_lr = []
threshold_metrics_rf = []

for threshold in thresholds:
    threshold_metrics_lr.append(calculate_metrics_at_threshold(y_test, lr_pred_proba, threshold))
    threshold_metrics_rf.append(calculate_metrics_at_threshold(y_test, rf_pred_proba, threshold))

df_thresholds_lr = pd.DataFrame(threshold_metrics_lr)
df_thresholds_rf = pd.DataFrame(threshold_metrics_rf)
```

### Зависимость метрик от порога: Logistic Regression

```{python}
#| label: thresh-lr
#| fig-cap: "Метрики vs Порог (Logistic Regression)"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
for metric in ['accuracy', 'precision', 'recall', 'f1']:
    plt.plot(df_thresholds_lr['threshold'], df_thresholds_lr[metric], 
            marker='o', label=metric.capitalize())

plt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Порог 0.5')
plt.xlabel('Порог классификации')
plt.ylabel('Значение метрики')
plt.title('Logistic Regression: Зависимость метрик от порога')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

### Зависимость метрик от порога: Random Forest

```{python}
#| label: thresh-rf
#| fig-cap: "Метрики vs Порог (Random Forest)"
#| fig-width: 10
#| fig-height: 6

plt.figure(figsize=(10, 6))
for metric in ['accuracy', 'precision', 'recall', 'f1']:
    plt.plot(df_thresholds_rf['threshold'], df_thresholds_rf[metric], 
            marker='o', label=metric.capitalize())

plt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Порог 0.5')
plt.xlabel('Порог классификации')
plt.ylabel('Значение метрики')
plt.title('Random Forest: Зависимость метрик от порога')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

Оптимальные пороги по F1-score:

```{python}
#| label: opt-thresh
optimal_threshold_lr = df_thresholds_lr.loc[df_thresholds_lr['f1'].idxmax(), 'threshold']
optimal_threshold_rf = df_thresholds_rf.loc[df_thresholds_rf['f1'].idxmax(), 'threshold']

print(f"Logistic Regression: {optimal_threshold_lr:.3f}")
print(f"Random Forest: {optimal_threshold_rf:.3f}")
```

# Обсуждение

## Ключевые findings

На основе проведенного анализа данных о сердечно-сосудистых заболеваниях были получены следующие ключевые результаты:

### Демографические характеристики

1. **Сбалансированная выборка**: распределение наличия/отсутствия заболевания практически сбалансировано (50.5% пациентов с заболеваниями против 49.5% без)
2. **Преобладание женщин**: в выборке представлено больше женщин, чем мужчин (примерно 65% против 35%)
3. **Возрастной диапазон**: пациенты в возрасте от 40 до 65 лет, что соответствует группе повышенного риска ССЗ

### Факторы риска

Наиболее значимыми факторами риска, выявленными в ходе анализа, являются:

1. **Артериальное давление** (систолическое и диастолическое) - самый сильный предиктор
2. **Возраст** - прямо коррелирует с вероятностью заболевания
3. **Уровень холестерина** - второй по важности фактор
4. **Индекс массы тела (BMI)** - избыточный вес и ожирение значимо повышают риск

### Качество моделей

Обе модели продемонстрировали качество выше требуемых порогов:

- **Random Forest**: AUC-ROC = 0.78 (превышает требование > 0.75)
- **Logistic Regression**: AUC-ROC = 0.76 (соответствует требованию)

Random Forest показывает незначительное преимущество по всем метрикам, однако Logistic Regression обладает лучшей интерпретируемостью.

## Практические рекомендации

### Для медицинской лаборатории

1. **Приоритетные показатели**: при скрининге следует уделять особое внимание артериальному давлению и уровню холестерина
2. **Возрастные группы**: пациенты старше 50 лет должны находиться в группе повышенного внимания
3. **BMI мониторинг**: регулярный контроль индекса массы тела для своевременного выявления рисков

### Критерии выбора модели

- **Random Forest** рекомендуется для автоматизированного скрининга (более высокая точность)
- **Logistic Regression** - для клинической практики (интерпретируемость коэффициентов)

## Ограничения исследования

1. **Отсутствие дополнительных факторов**: в данных нет информации о наследственности, питании, стрессовых факторах
2. **Популяционные особенности**: датасет может не полностью представлять все демографические группы
3. **Временные ограничения**: данные представляют срез во времени без анализа динамики

## Направления для будущих исследований

1. **Включение генетических маркеров** для более точной оценки риска
2. **Долгосрочное наблюдение** за пациентами для оценки прогрессии заболевания
3. **Интеграция с лабораторными анализами** (биохимические показатели крови)
4. **Разработка интерактивного калькулятора риска** для использования клиницистами

# Заключение

В ходе данного исследования был проведен комплексный анализ данных сердечно-сосудистых заболеваний с целью выявления ключевых факторов риска и разработки предиктивных моделей.

## Основные результаты

1. **Выявлены ключевые факторы риска**: артериальное давление, возраст, уровень холестерина и BMI являются наиболее значимыми предикторами наличия ССЗ

2. **Разработаны предиктивные модели**: обе модели (Logistic Regression и Random Forest) превышают требуемые пороги качества (AUC-ROC > 0.75)

3. **Обеспечена воспроизводимость**: полный анализ документирован с использованием Quarto, что гарантирует воспроизводимость результатов

4. **Созданы практические рекомендации**: разработаны конкретные рекомендации для медицинской лаборатории по использованию результатов анализа

## Вклад в практику

Результаты исследования могут быть использованы для:

- **Оптимизации скрининговых программ** - фокус на наиболее информативных показателях
- **Персонализации подхода** - учет индивидуальных факторов риска пациента
- **Повышения эффективности профилактики** - своевременное выявление групп риска
- **Автоматизации предварительной диагностики** - использование ML моделей для поддержки принятия решений

## Техническое достижение

Успешно реализован полный цикл анализа данных: от загрузки и очистки до построения и оценки моделей, с созданием полностью воспроизводимого исследования в формате Quarto документа.

Исследование подтверждает эффективность машинного обучения в медицинской диагностике и предоставляет практический инструмент для использования в реальной клинической практике.
