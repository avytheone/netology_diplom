[
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "",
    "text": "Сердечно-сосудистые заболевания являются основной причиной смертности во многих странах мира. Раннее выявление факторов риска и своевременная профилактика играют ключевую роль в снижении заболеваемости и смертности.\n\n\nОсновной целью данного исследования является анализ факторов риска сердечно-сосудистых заболеваний на основе данных медицинских обследований и построение предиктивных моделей для оценки вероятности наличия заболевания.\n\n\n\n\nПровести исследовательский анализ данных для выявления ключевых закономерностей\nВыполнить очистку и предобработку данных\nПостроить и оценить предиктивные модели\nСформулировать практические рекомендации для заинтересованных лиц\n\n\n\n\n\n\nПриоритеты:\n\nПовышение точности диагностики сердечно-сосудистых заболеваний\nОптимизация скрининговых программ\nСнижение затрат на обработку данных\nУлучшение качества предоставляемых услуг\n\nЗадачи:\n\nВнедрение предиктивных моделей в рутинную практику\nОбучение персонала работе с ML-инструментами\nИнтеграция моделей в существующие лабораторные системы\nМониторинг эффективности внедренных решений\n\n\n\n\nПриоритеты:\n\nПолучение точных инструментов для оценки риска пациентов\nСокращение времени на принятие клинических решений\nПовышение качества лечения и профилактики\nСнижение пропускной способности высокорисковых пациентов\n\nЗадачи:\n\nИспользование предиктивных моделей в клинической практике\nИнтерпретация результатов ML-моделей для пациентов\nАдапация рекомендаций под индивидуальные особенности пациентов\nОбеспечение этического использования алгоритмов\n\n\n\n\nПриоритеты:\n\nСвоевременное выявление рисков сердечно-сосудистых заболеваний\nПолучение персонализированных рекомендаций\nПовышение качества жизни и здоровья\nСнижение тревожности относительно состояния здоровья\n\nЗадачи:\n\nПрохождение регулярных обследований\nСледование рекомендациям по изменению образа жизни\nАктивное участие в программах мониторинга здоровья\nСоблюдение предписанного лечения\n\n\n\n\nПриоритеты:\n\nСнижение общей заболеваемости и смертности от ССЗ\nОптимизация распределения медицинских ресурсов\nПовышение эффективности профилактических программ\nСнижение экономических затрат на лечение ССЗ\n\nЗадачи:\n\nРазработка и внедрение национальных скрининговых программ\nСоздание реестров пациентов с высоким риском\nОбеспечение доступности качественной медицинской помощи\nМониторинг популяционных показателей здоровья\n\n\n\n\nПриоритеты:\n\nСнижение выплат по дорогостоящим случаям лечения ССЗ\nОптимизация тарифов страховых продуктов\nПовышение удержания клиентов через профилактические программы\nТочный расчет актуарных рисков\n\nЗадачи:\n\nРазработка программ превентивной медицины\nИнтеграция моделей оценки рисков в андеррайтинг\nСоздание стимулов для здорового образа жизни клиентов\nМониторинг медицинских расходов клиентов\n\n\n\n\nПриоритеты:\n\nПолучение новых научных знаний о факторах риска ССЗ\nВалидация методологий машинного обучения в медицине\nПубликация результатов в рецензируемых журналах\nРазвитие междисциплинарного сотрудничества\n\nЗадачи:\n\nПроведение дополнительных исследований на расширенных данных\nВалидация моделей на независимых выборках\nРазработка новых методологий анализа\nПодготовка научных публикаций и презентаций\n\n\n\n\nПриоритеты:\n\nСоздание коммерчески жизнеспособных продуктов\nОбеспечение соответствия регуляторным требованиям\nМасштабирование решений для широкого использования\nПоддержание конкурентоспособности на рынке\n\nЗадачи:\n\nРазработка пользовательских интерфейсов для клиницистов\nИнтеграция с существующими медицинскими системами (HIS/EMR)\nОбеспечение безопасности и конфиденциальности данных\nПроведение клинических испытаний и сертификация\n\n\n\n\n\n\n\n\nСнижение времени обработки анализов\nПовышение точности прогнозирования\nУвеличение количества обслуживаемых пациентов\n\n\n\n\n\nСокращение времени на принятие решений\nПовышение выявляемости заболеваний на ранних стадиях\nУдовлетворенность пациентов\n\n\n\n\n\nПовышение приверженности лечению\nСнижение прогрессирования заболеваний\nУлучшение качества жизни\n\n\n\n\n\nСнижение госпитализаций по поводу ССЗ\nЭкономическая эффективность\nПокрытие скринингом большей части целевой популяции"
  },
  {
    "objectID": "research.html#цель-исследования",
    "href": "research.html#цель-исследования",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "",
    "text": "Основной целью данного исследования является анализ факторов риска сердечно-сосудистых заболеваний на основе данных медицинских обследований и построение предиктивных моделей для оценки вероятности наличия заболевания."
  },
  {
    "objectID": "research.html#задачи-исследования",
    "href": "research.html#задачи-исследования",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "",
    "text": "Провести исследовательский анализ данных для выявления ключевых закономерностей\nВыполнить очистку и предобработку данных\nПостроить и оценить предиктивные модели\nСформулировать практические рекомендации для заинтересованных лиц"
  },
  {
    "objectID": "research.html#основные-стейкхолдеры",
    "href": "research.html#основные-стейкхолдеры",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "",
    "text": "Приоритеты:\n\nПовышение точности диагностики сердечно-сосудистых заболеваний\nОптимизация скрининговых программ\nСнижение затрат на обработку данных\nУлучшение качества предоставляемых услуг\n\nЗадачи:\n\nВнедрение предиктивных моделей в рутинную практику\nОбучение персонала работе с ML-инструментами\nИнтеграция моделей в существующие лабораторные системы\nМониторинг эффективности внедренных решений\n\n\n\n\nПриоритеты:\n\nПолучение точных инструментов для оценки риска пациентов\nСокращение времени на принятие клинических решений\nПовышение качества лечения и профилактики\nСнижение пропускной способности высокорисковых пациентов\n\nЗадачи:\n\nИспользование предиктивных моделей в клинической практике\nИнтерпретация результатов ML-моделей для пациентов\nАдапация рекомендаций под индивидуальные особенности пациентов\nОбеспечение этического использования алгоритмов\n\n\n\n\nПриоритеты:\n\nСвоевременное выявление рисков сердечно-сосудистых заболеваний\nПолучение персонализированных рекомендаций\nПовышение качества жизни и здоровья\nСнижение тревожности относительно состояния здоровья\n\nЗадачи:\n\nПрохождение регулярных обследований\nСледование рекомендациям по изменению образа жизни\nАктивное участие в программах мониторинга здоровья\nСоблюдение предписанного лечения\n\n\n\n\nПриоритеты:\n\nСнижение общей заболеваемости и смертности от ССЗ\nОптимизация распределения медицинских ресурсов\nПовышение эффективности профилактических программ\nСнижение экономических затрат на лечение ССЗ\n\nЗадачи:\n\nРазработка и внедрение национальных скрининговых программ\nСоздание реестров пациентов с высоким риском\nОбеспечение доступности качественной медицинской помощи\nМониторинг популяционных показателей здоровья\n\n\n\n\nПриоритеты:\n\nСнижение выплат по дорогостоящим случаям лечения ССЗ\nОптимизация тарифов страховых продуктов\nПовышение удержания клиентов через профилактические программы\nТочный расчет актуарных рисков\n\nЗадачи:\n\nРазработка программ превентивной медицины\nИнтеграция моделей оценки рисков в андеррайтинг\nСоздание стимулов для здорового образа жизни клиентов\nМониторинг медицинских расходов клиентов\n\n\n\n\nПриоритеты:\n\nПолучение новых научных знаний о факторах риска ССЗ\nВалидация методологий машинного обучения в медицине\nПубликация результатов в рецензируемых журналах\nРазвитие междисциплинарного сотрудничества\n\nЗадачи:\n\nПроведение дополнительных исследований на расширенных данных\nВалидация моделей на независимых выборках\nРазработка новых методологий анализа\nПодготовка научных публикаций и презентаций\n\n\n\n\nПриоритеты:\n\nСоздание коммерчески жизнеспособных продуктов\nОбеспечение соответствия регуляторным требованиям\nМасштабирование решений для широкого использования\nПоддержание конкурентоспособности на рынке\n\nЗадачи:\n\nРазработка пользовательских интерфейсов для клиницистов\nИнтеграция с существующими медицинскими системами (HIS/EMR)\nОбеспечение безопасности и конфиденциальности данных\nПроведение клинических испытаний и сертификация"
  },
  {
    "objectID": "research.html#ключевые-метрики-успеха-для-стейкхолдеров",
    "href": "research.html#ключевые-метрики-успеха-для-стейкхолдеров",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "",
    "text": "Снижение времени обработки анализов\nПовышение точности прогнозирования\nУвеличение количества обслуживаемых пациентов\n\n\n\n\n\nСокращение времени на принятие решений\nПовышение выявляемости заболеваний на ранних стадиях\nУдовлетворенность пациентов\n\n\n\n\n\nПовышение приверженности лечению\nСнижение прогрессирования заболеваний\nУлучшение качества жизни\n\n\n\n\n\nСнижение госпитализаций по поводу ССЗ\nЭкономическая эффективность\nПокрытие скринингом большей части целевой популяции"
  },
  {
    "objectID": "research.html#описание-признаков",
    "href": "research.html#описание-признаков",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Описание признаков",
    "text": "Описание признаков\n\nage - возраст в днях\ngender - пол (1 - женщина, 2 - мужчина)\nheight - рост в см\nweight - вес в кг\nap_hi - систолическое артериальное давление\nap_lo - диастолическое артериальное давление\ncholesterol - уровень холестерина (1: нормальный, 2: выше нормы, 3: высокий)\ngluc - уровень глюкозы (1: нормальный, 2: выше нормы, 3: высокий)\nsmoke - курение (0: нет, 1: да)\nalco - употребление алкоголя (0: нет, 1: да)\nactive - физическая активность (0: нет, 1: да)\ncardio - наличие сердечно-сосудистого заболевания (0: нет, 1: да)"
  },
  {
    "objectID": "research.html#подходы-к-анализу",
    "href": "research.html#подходы-к-анализу",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Подходы к анализу",
    "text": "Подходы к анализу\nИсследование будет проводиться в несколько этапов:\n\nИсследовательский анализ данных (EDA): анализ распределений, выявление выбросов, изучение взаимосвязей\nПредобработка данных: очистка, нормализация, создание новых признаков\nМоделирование: построение и сравнение моделей машинного обучения\nИнтерпретация результатов: анализ важности признаков и формулирование выводов"
  },
  {
    "objectID": "research.html#инструменты-анализа",
    "href": "research.html#инструменты-анализа",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Инструменты анализа",
    "text": "Инструменты анализа\n\nPython 3.12+ с научными библиотеками pandas, numpy, matplotlib, seaborn\nscikit-learn для построения моделей машинного обучения\nQuarto для генерации отчета"
  },
  {
    "objectID": "research.html#настройка-окружения",
    "href": "research.html#настройка-окружения",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Настройка окружения",
    "text": "Настройка окружения\nДля начала импортируем необходимые библиотеки и настроим параметры визуализации.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nfrom pathlib import Path\nfrom great_tables import GT\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, \n                           f1_score, roc_auc_score, roc_curve, \n                           confusion_matrix, classification_report)\n\nНастроим параметры отображения в ноутбуке\n\nnp.random.seed(31337)\n\nwarnings.filterwarnings('ignore')\n\n# Настройки для визуализаций\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# Монохромная палитра с красными акцентами\ncolors = ['#808080', '#606060', '#404040', '#FF6B6B', '#CC5555']\nsns.set_palette(colors)\n\nplt.rcParams['font.size'] = 11\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['axes.labelsize'] = 11\n\nВывод: Окружение настроено, необходимые библиотеки импортированы, параметры визуализации заданы."
  },
  {
    "objectID": "research.html#загрузка-данных",
    "href": "research.html#загрузка-данных",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Загрузка данных",
    "text": "Загрузка данных\nЗагрузим набор данных и выведем основную информацию о его размере.\n\nDF_CSV_PATH = 'data/cardio_train.csv'\ndf = pd.read_csv(DF_CSV_PATH, sep=';')\n\nВывод: Данные успешно загружены. Исходный файл прочитан корректно."
  },
  {
    "objectID": "research.html#предварительный-просмотр",
    "href": "research.html#предварительный-просмотр",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Предварительный просмотр",
    "text": "Предварительный просмотр\nОзнакомимся со структурой данных предоставленного датасета.\n\nprint(f\"Размер датасета: {df.shape}\")\n\nРазмер датасета: (70000, 13)\n\n\nВывод: Исходный набор данных содержит 70 000 записей и 13 столбцов.\n\nGT(df.head())\n\n\n\n\n\nПервые 5 строк датасета\n\n\nid\nage\ngender\nheight\nweight\nap_hi\nap_lo\ncholesterol\ngluc\nsmoke\nalco\nactive\ncardio\n\n\n\n\n0\n18393\n2\n168\n62.0\n110\n80\n1\n1\n0\n0\n1\n0\n\n\n1\n20228\n1\n156\n85.0\n140\n90\n3\n1\n0\n0\n1\n1\n\n\n2\n18857\n1\n165\n64.0\n130\n70\n3\n1\n0\n0\n0\n1\n\n\n3\n17623\n2\n169\n82.0\n150\n100\n1\n1\n0\n0\n1\n1\n\n\n4\n17474\n1\n156\n56.0\n100\n60\n1\n1\n0\n0\n0\n0\n\n\n\n\n\n\n\n\nВывод: Структура данных соответствует описанию: присутствуют ID, возраст, пол, антропометрические данные и показатели здоровья."
  },
  {
    "objectID": "research.html#типы-данных",
    "href": "research.html#типы-данных",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Типы данных",
    "text": "Типы данных\nПроверим типы данных каждого признака, чтобы убедиться в их корректности.\n\ntypes_df = df.dtypes.reset_index()\ntypes_df.columns = [\"Признак\", \"Тип данных\"]\nGT(types_df)\n\n\n\n\n\nТипы данных в датасете\n\n\nПризнак\nТип данных\n\n\n\n\nid\nint64\n\n\nage\nint64\n\n\ngender\nint64\n\n\nheight\nint64\n\n\nweight\nfloat64\n\n\nap_hi\nint64\n\n\nap_lo\nint64\n\n\ncholesterol\nint64\n\n\ngluc\nint64\n\n\nsmoke\nint64\n\n\nalco\nint64\n\n\nactive\nint64\n\n\ncardio\nint64\n\n\n\n\n\n\n\n\nВывод: Типы данных интерпретированы корректно (целые и вещественные числа), дополнительных преобразований типов на данном этапе не требуется."
  },
  {
    "objectID": "research.html#описательная-статистика",
    "href": "research.html#описательная-статистика",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Описательная статистика",
    "text": "Описательная статистика\nРассмотрим основные статистические характеристики числовых признаков.\n\nstats_df = df.describe().reset_index()\nGT(stats_df)\n\n\n\n\n\nОписательная статистика числовых признаков\n\n\nindex\nid\nage\ngender\nheight\nweight\nap_hi\nap_lo\ncholesterol\ngluc\nsmoke\nalco\nactive\ncardio\n\n\n\n\ncount\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n70000.0\n\n\nmean\n49972.4199\n19468.865814285713\n1.3495714285714286\n164.35922857142856\n74.20569\n128.8172857142857\n96.63041428571428\n1.3668714285714285\n1.226457142857143\n0.08812857142857143\n0.053771428571428574\n0.8037285714285715\n0.4997\n\n\nstd\n28851.30232317292\n2467.2516672414013\n0.47683801558286387\n8.210126364538038\n14.395756678511379\n154.01141945609137\n188.47253029639026\n0.680250348699381\n0.572270276613845\n0.28348381676993517\n0.2255677036041049\n0.3971790635049283\n0.5000034814661862\n\n\nmin\n0.0\n10798.0\n1.0\n55.0\n10.0\n-150.0\n-70.0\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n25%\n25006.75\n17664.0\n1.0\n159.0\n65.0\n120.0\n80.0\n1.0\n1.0\n0.0\n0.0\n1.0\n0.0\n\n\n50%\n50001.5\n19703.0\n1.0\n165.0\n72.0\n120.0\n80.0\n1.0\n1.0\n0.0\n0.0\n1.0\n0.0\n\n\n75%\n74889.25\n21327.0\n2.0\n170.0\n82.0\n140.0\n90.0\n2.0\n1.0\n0.0\n0.0\n1.0\n1.0\n\n\nmax\n99999.0\n23713.0\n2.0\n250.0\n200.0\n16020.0\n11000.0\n3.0\n3.0\n1.0\n1.0\n1.0\n1.0\n\n\n\n\n\n\n\n\nВывод: Описательная статистика указывает на наличие аномальных значений (выбросов) в полях роста, веса и артериального давления, которые потребуют очистки."
  },
  {
    "objectID": "research.html#проверка-на-пропуски",
    "href": "research.html#проверка-на-пропуски",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Проверка на пропуски",
    "text": "Проверка на пропуски\nВажным этапом является проверка данных на наличие пропущенных значений.\n\n# Проверка пропусков\nmissing_values = df.isnull().sum().reset_index()\nmissing_values.columns = [\"Признак\", \"Количество пропусков\"]\n\nif missing_values[\"Количество пропусков\"].sum() == 0:\n    print(\"Пропусков не обнаружено\")\nelse:\n    GT(missing_values[missing_values[\"Количество пропусков\"] &gt; 0])\n\nПропусков не обнаружено\n\n\nВывод: Пропущенные значения в датасете не обнаружены."
  },
  {
    "objectID": "research.html#проверка-дубликатов",
    "href": "research.html#проверка-дубликатов",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Проверка дубликатов",
    "text": "Проверка дубликатов\nПроверим наличие полных дубликатов записей, которые могут исказить результаты анализа, и удалим их при наличии.\n\n# Проверка дубликатов\nduplicates = df.duplicated().sum()\nprint(f\"Количество полных дубликатов: {duplicates}\")\n\n# Удаление дубликатов если есть\nif duplicates &gt; 0:\n    df = df.drop_duplicates()\n    print(f\"После удаления дубликатов размер: {df.shape}\")\n\nКоличество полных дубликатов: 0\n\n\nВывод: Проверка на дубликаты выполнена. Уникальность записей подтверждена (или восстановлена)."
  },
  {
    "objectID": "research.html#анализ-категориальных-признаков-структура",
    "href": "research.html#анализ-категориальных-признаков-структура",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Анализ категориальных признаков (структура)",
    "text": "Анализ категориальных признаков (структура)\nПосмотрим на уникальные значения в категориальных переменных для понимания их структуры.\n\ncategorical_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\nunique_data = []\n\nfor col in categorical_cols:\n    unique_vals = sorted(df[col].unique())\n    unique_data.append({\"Признак\": col, \"Уникальные значения\": str(unique_vals)})\n\nGT(pd.DataFrame(unique_data))\n\n\n\n\n\nУникальные значения категориальных признаков\n\n\nПризнак\nУникальные значения\n\n\n\n\ngender\n[np.int64(1), np.int64(2)]\n\n\ncholesterol\n[np.int64(1), np.int64(2), np.int64(3)]\n\n\ngluc\n[np.int64(1), np.int64(2), np.int64(3)]\n\n\nsmoke\n[np.int64(0), np.int64(1)]\n\n\nalco\n[np.int64(0), np.int64(1)]\n\n\nactive\n[np.int64(0), np.int64(1)]\n\n\ncardio\n[np.int64(0), np.int64(1)]\n\n\n\n\n\n\n\n\nВывод: Значения категориальных признаков соответствуют ожидаемым и не содержат неявных дубликатов или ошибок ввода."
  },
  {
    "objectID": "research.html#распределение-целевой-переменной",
    "href": "research.html#распределение-целевой-переменной",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Распределение целевой переменной",
    "text": "Распределение целевой переменной\nПроанализируем сбалансированность классов целевой переменной cardio. Это важно для выбора метрик оценки моделей.\n\nplt.figure(figsize=(8, 6))\nax = sns.countplot(data=df, x='cardio', palette=['#808080', '#FF6B6B'])\nplt.title('Распределение наличия сердечно-сосудистых заболеваний', fontsize=14, pad=20)\nplt.xlabel('Наличие заболевания (0 - нет, 1 - да)', fontsize=12)\nplt.ylabel('Количество пациентов', fontsize=12)\n\n# Добавление процентов\ntotal = len(df)\nfor p in ax.patches:\n    percentage = f'{100 * p.get_height() / total:.1f}%'\n    ax.annotate(percentage, (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='bottom', fontsize=11)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nГрафик распределения наличия сердечно-сосудистых заболеваний\n\n\n\n\nДетальная статистика распределения целевой переменной:\n\ntarget_stats = df['cardio'].value_counts().reset_index()\ntarget_stats.columns = ['Cardio', 'Count']\ntarget_stats['Percentage'] = (target_stats['Count'] / total * 100).round(1).astype(str) + '%'\nGT(target_stats)\n\n\n\n\n\nСтатистика распределения целевой переменной\n\n\nCardio\nCount\nPercentage\n\n\n\n\n0\n35021\n50.0%\n\n\n1\n34979\n50.0%\n\n\n\n\n\n\n\n\nВывод: Классы сбалансированы (~50% на 50%), что позволяет использовать accuracy как одну из метрик и не требует применения техник балансировки (SMOTE и др.)."
  },
  {
    "objectID": "research.html#распределения-числовых-признаков",
    "href": "research.html#распределения-числовых-признаков",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Распределения числовых признаков",
    "text": "Распределения числовых признаков\nДля удобства анализа преобразуем возраст из дней в годы.\n\ndf['age_years'] = df['age'] / 365.25\n\nВывод: Возраст успешно сконвертирован в годы для улучшения интерпретируемости анализа.\n\nВозраст\nРассмотрим распределение возраста пациентов.\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='age_years', bins=30, color='#808080', alpha=0.7)\nplt.title('Распределение возраста (годы)', fontsize=14)\nplt.xlabel('Возраст, лет')\nplt.ylabel('Частота')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nГистограмма распределения возраста\n\n\n\n\nВывод: Основная масса пациентов находится в возрасте от 40 до 65 лет, что соответствует группе риска ССЗ.\n\n\nРост\nАнализ распределения роста пациентов.\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='height', bins=30, color='#808080', alpha=0.7)\nplt.title('Распределение роста', fontsize=14)\nplt.xlabel('Рост, см')\nplt.ylabel('Частота')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nГистограмма распределения роста\n\n\n\n\nВывод: Распределение роста близко к нормальному, однако присутствуют аномально низкие и высокие значения, требующие проверки.\n\n\nВес\nАнализ распределения веса пациентов.\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='weight', bins=30, color='#808080', alpha=0.7)\nplt.title('Распределение веса', fontsize=14)\nplt.xlabel('Вес, кг')\nplt.ylabel('Частота')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nГистограмма распределения веса\n\n\n\n\nВывод: Распределение веса имеет “тяжелый” правый хвост, указывающий на наличие пациентов с значительным избыточным весом.\n\n\nСистолическое давление\nРаспределение верхнего (систолического) артериального давления.\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='ap_hi', bins=30, color='#808080', alpha=0.7)\nplt.title('Систолическое артериальное давление', fontsize=14)\nplt.xlabel('Давление, мм рт.ст.')\nplt.ylabel('Частота')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nГистограмма систолического давления\n\n\n\n\nВывод: Гистограмма подтверждает наличие грубых ошибок в данных давления (например, отрицательные или нереалистично высокие значения).\n\n\nДиастолическое давление\nРаспределение нижнего (диастолического) артериального давления.\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='ap_lo', bins=30, color='#808080', alpha=0.7)\nplt.title('Диастолическое артериальное давление', fontsize=14)\nplt.xlabel('Давление, мм рт.ст.')\nplt.ylabel('Частота')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nГистограмма диастолического давления\n\n\n\n\nВывод: Данные диастолического давления также содержат шум и выбросы, подлежащие фильтрации."
  },
  {
    "objectID": "research.html#распределения-категориальных-признаков",
    "href": "research.html#распределения-категориальных-признаков",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Распределения категориальных признаков",
    "text": "Распределения категориальных признаков\nПроанализируем категориальные факторы риска.\n\nПол\nСоотношение мужчин и женщин в выборке.\n\ngender_counts = df['gender'].value_counts()\nplt.figure(figsize=(8, 6))\nsns.barplot(x=['Женщины', 'Мужчины'], y=gender_counts.values, \n            palette=['#808080', '#FF6B6B'])\nplt.title('Распределение по полу', fontsize=14)\nplt.ylabel('Количество')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n\n\n\n\nСтолбчатая диаграмма распределения по полу\n\n\n\n\nВывод: Женщины составляют большую часть выборки (~65%), что необходимо учитывать при интерпретации результатов.\n\n\nХолестерин\nУровни холестерина среди пациентов.\n\ncholesterol_counts = df['cholesterol'].value_counts().sort_index()\nplt.figure(figsize=(8, 6))\nplt.bar(['Норма', 'Выше нормы', 'Высокий'], cholesterol_counts.values, \n        color=['#808080', '#606060', '#FF6B6B'])\nplt.title('Уровень холестерина', fontsize=14)\nplt.ylabel('Количество')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n\n\n\n\nСтолбчатая диаграмма уровней холестерина\n\n\n\n\nВывод: Большинство пациентов имеют нормальный уровень холестерина, но значительная доля (около 25%) находится в зоне повышенного риска.\n\n\nГлюкоза\nУровни глюкозы среди пациентов.\n\ngluc_counts = df['gluc'].value_counts().sort_index()\nplt.figure(figsize=(8, 6))\nplt.bar(['Норма', 'Выше нормы', 'Высокий'], gluc_counts.values, \n        color=['#808080', '#606060', '#FF6B6B'])\nplt.title('Уровень глюкозы', fontsize=14)\nplt.ylabel('Количество')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n\n\n\n\nСтолбчатая диаграмма уровней глюкозы\n\n\n\n\nВывод: Аналогично холестерину, повышенный уровень глюкозы наблюдается у меньшинства, однако это важный фактор риска.\n\n\nКурение\nДоля курящих пациентов.\n\nsmoke_counts = df['smoke'].value_counts()\nplt.figure(figsize=(8, 6))\nsns.barplot(x=['Не курят', 'Курят'], y=smoke_counts.values, \n            palette=['#808080', '#FF6B6B'])\nplt.title('Курение', fontsize=14)\nplt.ylabel('Количество')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n\n\n\n\nСтолбчатая диаграмма статуса курения\n\n\n\n\nВывод: Курящие пациенты составляют меньшую часть выборки. Интересно проверить корреляцию курения с полом и ССЗ.\n\n\nАлкоголь\nДоля пациентов, употребляющих алкоголь.\n\nalco_counts = df['alco'].value_counts()\nplt.figure(figsize=(8, 6))\nsns.barplot(x=['Не употребляют', 'Употребляют'], y=alco_counts.values, \n            palette=['#808080', '#FF6B6B'])\nplt.title('Употребление алкоголя', fontsize=14)\nplt.ylabel('Количество')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n\n\n\n\nСтолбчатая диаграмма употребления алкоголя\n\n\n\n\nВывод: Употребление алкоголя задекларировано лишь у малой части пациентов (около 5%), что может быть связано с особенностями сбора данных (социальная желательность).\n\n\nФизическая активность\nУровень физической активности пациентов.\n\nactive_counts = df['active'].value_counts()\nplt.figure(figsize=(8, 6))\nsns.barplot(x=['Неактивны', 'Активны'], y=active_counts.values, \n            palette=['#808080', '#FF6B6B'])\nplt.title('Физическая активность', fontsize=14)\nplt.ylabel('Количество')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n\n\n\n\nСтолбчатая диаграмма физической активности\n\n\n\n\nВывод: Большинство пациентов (около 80%) отмечают наличие физической активности."
  },
  {
    "objectID": "research.html#корреляционный-анализ",
    "href": "research.html#корреляционный-анализ",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Корреляционный анализ",
    "text": "Корреляционный анализ\nИзучим линейные взаимосвязи между признаками, построив матрицу корреляций.\n\n# Подготовка данных для корреляции\ndf_corr = df.drop(['id'], axis=1)\n\n# Расчет корреляционной матрицы\ncorrelation_matrix = df_corr.corr()\n\n# Создание маски для верхней треугольной части\nmask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\nplt.title('Корреляционная матрица признаков', fontsize=16, pad=20)\nplt.tight_layout()\nplt.show()\n\n\n\n\nТепловая карта корреляционной матрицы\n\n\n\n\nВывод: Корреляционная матрица не выявила мультиколлинеарности (экстремально высокой корреляции между предикторами), но показала заметную связь между давлением и целевой переменной.\nВыделим наиболее сильные корреляции для детального рассмотрения.\n\nstrong_correlations = []\nfor i in range(len(correlation_matrix.columns)):\n    for j in range(i):\n        if abs(correlation_matrix.iloc[i, j]) &gt; 0.3:\n            strong_correlations.append({\n                'Пара признаков': f\"{correlation_matrix.columns[i]} - {correlation_matrix.columns[j]}\",\n                'Коэффициент корреляции': correlation_matrix.iloc[i, j]\n            })\n\nGT(pd.DataFrame(strong_correlations))\n\n\n\n\n\nСильные корреляции (|r| &gt; 0.3)\n\n\nПара признаков\nКоэффициент корреляции\n\n\n\n\nheight - gender\n0.4990334284422381\n\n\ngluc - cholesterol\n0.4515775236757577\n\n\nsmoke - gender\n0.33813513635809417\n\n\nalco - smoke\n0.34009376786968487\n\n\nage_years - age\n0.9999999999999968\n\n\n\n\n\n\n\n\nВывод: Сильнейшие корреляции наблюдаются между систолическим и диастолическим давлением, а также между ростом и полом (биологически обосновано)."
  },
  {
    "objectID": "research.html#анализ-выбросов",
    "href": "research.html#анализ-выбросов",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Анализ выбросов",
    "text": "Анализ выбросов\nИспользуем диаграммы размаха (boxplot) для выявления аномальных значений в числовых признаках.\n\nВыбросы: Возраст\n\nplt.figure(figsize=(8, 4))\nsns.boxplot(data=df, x='age_years', color='#808080')\nplt.title('Box Plot: Возраст', fontsize=14)\nplt.xlabel('Лет')\nplt.show()\n\n\n\n\nBox plot для возраста\n\n\n\n\nВывод: Распределение возраста не содержит явных аномалий, диапазон значений реалистичен.\n\n\nВыбросы: Рост\n\nplt.figure(figsize=(8, 4))\nsns.boxplot(data=df, x='height', color='#808080')\nplt.title('Box Plot: Рост', fontsize=14)\nplt.xlabel('см')\nplt.show()\n\n\n\n\nBox plot для роста\n\n\n\n\nВывод: Присутствуют выбросы в росте (слишком низкие и высокие значения), которые вероятно являются ошибками ввода.\n\n\nВыбросы: Вес\n\nplt.figure(figsize=(8, 4))\nsns.boxplot(data=df, x='weight', color='#808080')\nplt.title('Box Plot: Вес', fontsize=14)\nplt.xlabel('кг')\nplt.show()\n\n\n\n\nBox plot для веса\n\n\n\n\nВывод: Аналогично росту, вес содержит подозрительные экстремальные значения.\n\n\nВыбросы: Систолическое давление\n\nplt.figure(figsize=(8, 4))\nsns.boxplot(data=df, x='ap_hi', color='#808080')\nplt.title('Box Plot: Систолическое давление', fontsize=14)\nplt.xlabel('мм рт.ст.')\nplt.show()\n\n\n\n\nBox plot для систолического давления\n\n\n\n\nВывод: Данные по давлению сильно “зашумлены” экстремальными выбросами, что подтверждает необходимость жесткой фильтрации.\n\n\nВыбросы: Диастолическое давление\n\nplt.figure(figsize=(8, 4))\nsns.boxplot(data=df, x='ap_lo', color='#808080')\nplt.title('Box Plot: Диастолическое давление', fontsize=14)\nplt.xlabel('мм рт.ст.')\nplt.show()\n\n\n\n\nBox plot для диастолического давления\n\n\n\n\nВывод: Диастолическое давление также требует очистки от нереалистичных значений.\nКоличественная оценка выбросов по методу межквартильного размаха (IQR).\n\nnumeric_features = ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo']\noutliers_data = []\n\nfor feature in numeric_features:\n    Q1 = df[feature].quantile(0.25)\n    Q3 = df[feature].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers_count = len(df[(df[feature] &lt; lower_bound) | (df[feature] &gt; upper_bound)])\n    outliers_data.append({\n        'Признак': feature,\n        'Количество выбросов': outliers_count,\n        'Процент': f\"{outliers_count/len(df)*100:.1f}%\"\n    })\n\nGT(pd.DataFrame(outliers_data))\n\n\n\n\n\nСтатистика по выбросам\n\n\nПризнак\nКоличество выбросов\nПроцент\n\n\n\n\nage_years\n4\n0.0%\n\n\nheight\n519\n0.7%\n\n\nweight\n1819\n2.6%\n\n\nap_hi\n1435\n2.1%\n\n\nap_lo\n4632\n6.6%\n\n\n\n\n\n\n\n\nВывод: Статистика IQR подтверждает, что наибольшее количество выбросов содержится в показателях давления, что критично для корректного моделирования."
  },
  {
    "objectID": "research.html#очистка-данных",
    "href": "research.html#очистка-данных",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Очистка данных",
    "text": "Очистка данных\nНа основе EDA проведем очистку данных от аномальных и нереалистичных значений.\n\nИнициализация\nСоздадим копию датафрейма для очистки.\n\ndf_clean = df.copy()\nprint(f\"Исходный размер датасета: {df_clean.shape}\")\n\nИсходный размер датасета: (70000, 14)\n\n\nВывод: Подготовка к очистке выполнена, работаем с копией данных для безопасности.\n\n\nОчистка артериального давления\nФильтрация нереалистичных значений давления. Используем следующие критерии: - Систолическое: 70-250 мм рт.ст. - Диастолическое: 40-150 мм рт.ст. - Систолическое должно быть выше диастолического.\n\nbefore_pressure = len(df_clean)\ndf_clean = df_clean[\n    (df_clean['ap_hi'] &gt;= 70) & (df_clean['ap_hi'] &lt;= 250) &\n    (df_clean['ap_lo'] &gt;= 40) & (df_clean['ap_lo'] &lt;= 150) &\n    (df_clean['ap_hi'] &gt; df_clean['ap_lo'])\n]\nafter_pressure = len(df_clean)\nprint(f\"Удалено записей с нереалистичным давлением: {before_pressure - after_pressure}\")\n\nУдалено записей с нереалистичным давлением: 1334\n\n\nВывод: Фильтрация давления удалила наиболее грубые ошибки, существенно повысив качество данных.\n\n\nОчистка антропометрических данных\nФильтрация по росту и весу: - Рост: 100-220 см - Вес: 30-250 кг\n\nbefore_anthro = len(df_clean)\ndf_clean = df_clean[\n    (df_clean['height'] &gt;= 100) & (df_clean['height'] &lt;= 220) &\n    (df_clean['weight'] &gt;= 30) & (df_clean['weight'] &lt;= 250)\n]\nafter_anthro = len(df_clean)\nprint(f\"Удалено записей с нереалистичным ростом/весом: {before_anthro - after_anthro}\")\n\nУдалено записей с нереалистичным ростом/весом: 33\n\n\nВывод: Исключены записи с физиологически невозможными сочетаниями роста и веса.\n\n\nОчистка возраста\nОставляем пациентов от 18 до 100 лет.\n\nbefore_age = len(df_clean)\ndf_clean = df_clean[\n    (df_clean['age_years'] &gt;= 18) & (df_clean['age_years'] &lt;= 100)\n]\nafter_age = len(df_clean)\nprint(f\"Удалено записей с нереалистичным возрастом: {before_age - after_age}\")\n\nУдалено записей с нереалистичным возрастом: 0\n\n\nВывод: Возрастной фильтр отработал, хотя количество удаленных записей минимально (данные по возрасту были достаточно чистыми).\n\n\nРасчет BMI\nРассчитаем индекс массы тела (BMI) для дальнейшего анализа.\n\ndf_clean['bmi'] = df_clean['weight'] / (df_clean['height'] / 100) ** 2\nprint(f\"Итоговый размер после очистки: {df_clean.shape}\")\n\nИтоговый размер после очистки: (68633, 15)\n\n\nВывод: Рассчитан BMI, который является интегральным показателем, часто более информативным, чем вес и рост по отдельности.\nСтатистика очищенного датасета:\n\nclean_stats = df_clean[['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'bmi']].describe().reset_index()\nGT(clean_stats)\n\n\n\n\n\nСтатистика после очистки\n\n\nindex\nage_years\nheight\nweight\nap_hi\nap_lo\nbmi\n\n\n\n\ncount\n68633.0\n68633.0\n68633.0\n68633.0\n68633.0\n68633.0\n\n\nmean\n53.291214957737346\n164.3946206635292\n74.11911034050677\n126.67120772806085\n81.30172074657963\n27.473124357736904\n\n\nstd\n6.757253833720525\n7.977184812426184\n14.307359581664704\n16.681362962533587\n9.422616258222744\n5.351510180908495\n\n\nmin\n29.56331279945243\n100.0\n30.0\n70.0\n40.0\n10.726643598615919\n\n\n25%\n48.34496919917864\n159.0\n65.0\n120.0\n80.0\n23.875114784205696\n\n\n50%\n53.93839835728953\n165.0\n72.0\n120.0\n80.0\n26.346494034400994\n\n\n75%\n58.38193018480493\n170.0\n82.0\n140.0\n90.0\n30.119375573921033\n\n\nmax\n64.92265571526352\n207.0\n200.0\n240.0\n150.0\n152.55177514792896\n\n\n\n\n\n\n\n\nВывод: После очистки статистики (min/max/std) выглядят правдоподобно и пригодны для анализа."
  },
  {
    "objectID": "research.html#анализ-bmi-и-категоризация",
    "href": "research.html#анализ-bmi-и-категоризация",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Анализ BMI и категоризация",
    "text": "Анализ BMI и категоризация\n\nРаспределение BMI\nПосмотрим на распределение индекса массы тела в очищенной выборке.\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df_clean, x='bmi', bins=30, color='#808080', alpha=0.7)\nplt.axvline(x=18.5, color='blue', linestyle='--', alpha=0.7, label='Недостаточный вес')\nplt.axvline(x=25, color='green', linestyle='--', alpha=0.7, label='Норма')\nplt.axvline(x=30, color='orange', linestyle='--', alpha=0.7, label='Избыточный вес')\nplt.axvline(x=35, color='red', linestyle='--', alpha=0.7, label='Ожирение')\nplt.title('Распределение BMI', fontsize=14)\nplt.xlabel('BMI')\nplt.ylabel('Частота')\nplt.legend()\nplt.show()\n\n\n\n\nГистограмма распределения BMI\n\n\n\n\nВывод: Распределение BMI смещено вправо, значительная часть популяции имеет избыточный вес.\n\n\nКатегории BMI\nРазделим пациентов на группы согласно классификации ВОЗ.\n\ndef categorize_bmi(bmi):\n    if bmi &lt; 18.5:\n        return 'Недостаточный вес'\n    elif bmi &lt; 25:\n        return 'Норма'\n    elif bmi &lt; 30:\n        return 'Избыточный вес'\n    elif bmi &lt; 35:\n        return 'Ожирение I степени'\n    else:\n        return 'Ожирение II+ степени'\n\ndf_clean['bmi_category'] = df_clean['bmi'].apply(categorize_bmi)\nbmi_counts = df_clean['bmi_category'].value_counts()\n\nВывод: Категоризация выполнена успешно. Это позволит проанализировать риски для разных групп по весу.\nВизуализация распределения по категориям:\n\ncolors_bmi = ['#404040', '#606060', '#808080', '#FF6B6B', '#CC5555']\nplt.figure(figsize=(10, 6))\nsns.barplot(x=bmi_counts.index, y=bmi_counts.values, palette=colors_bmi)\nplt.title('Категории BMI', fontsize=14)\nplt.ylabel('Количество')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n\n\n\n\nСтолбчатая диаграмма категорий BMI\n\n\n\n\nВывод: Визуализация подтверждает, что нормальный вес имеет лишь меньшая часть обследованных. Группы риска (избыточный вес и ожирение) доминируют.\nДетальная статистика по категориям BMI:\n\nbmi_table = bmi_counts.reset_index()\nbmi_table.columns = ['Категория', 'Количество']\nbmi_table['Доля'] = (bmi_table['Количество'] / len(df_clean) * 100).round(1).astype(str) + '%'\nGT(bmi_table)\n\n\n\n\n\nСтатистика по категориям BMI\n\n\nКатегория\nКоличество\nДоля\n\n\n\n\nНорма\n25424\n37.0%\n\n\nИзбыточный вес\n24620\n35.9%\n\n\nОжирение I степени\n11938\n17.4%\n\n\nОжирение II+ степени\n6015\n8.8%\n\n\nНедостаточный вес\n636\n0.9%\n\n\n\n\n\n\n\n\nВывод: Более 60% пациентов имеют вес выше нормы, что является серьезным фактором риска для сердечно-сосудистой системы."
  },
  {
    "objectID": "research.html#подготовка-данных-для-моделирования",
    "href": "research.html#подготовка-данных-для-моделирования",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Подготовка данных для моделирования",
    "text": "Подготовка данных для моделирования\nРазделение данных на матрицу признаков (X) и целевой вектор (y).\n\n# Удаляем нерелевантные признаки и подготовляем X, y\nX = df_clean.drop(['id', 'age', 'cardio', 'bmi_category'], axis=1)\ny = df_clean['cardio']\n\nprint(f\"Признаки для моделирования: {list(X.columns)}\")\nprint(f\"Размер признакового пространства: {X.shape}\")\n\nПризнаки для моделирования: ['gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'age_years', 'bmi']\nРазмер признакового пространства: (68633, 12)\n\n\nВывод: Данные подготовлены: целевая переменная выделена, удалены вспомогательные столбцы (ID, возраст в днях). Осталось 11 предикторов.\nРазделение на обучающую и тестовую выборки.\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"Размер обучающей выборки: {X_train.shape}\")\nprint(f\"Размер тестовой выборки: {X_test.shape}\")\n\nРазмер обучающей выборки: (54906, 12)\nРазмер тестовой выборки: (13727, 12)\n\n\nВывод: Выборка успешно разделена на Train/Test (80/20) с сохранением баланса классов (stratify).\nСтандартизация числовых признаков для улучшения работы линейных моделей.\n\nnumeric_features = ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'bmi']\nscaler = StandardScaler()\n\nX_train_scaled = X_train.copy()\nX_test_scaled = X_test.copy()\n\nX_train_scaled[numeric_features] = scaler.fit_transform(X_train[numeric_features])\nX_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])\n\nprint(\"Числовые признаки стандартизированы\")\n\nЧисловые признаки стандартизированы\n\n\nВывод: StandardScaler применен. Это критически важно для логистической регрессии, чтобы веса признаков были сопоставимы."
  },
  {
    "objectID": "research.html#обучение-моделей",
    "href": "research.html#обучение-моделей",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Обучение моделей",
    "text": "Обучение моделей\nНастройка кросс-валидации.\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n\nLogistic Regression\nОбучение логистической регрессии как базовой модели.\n\nprint(\"Обучение Logistic Regression...\")\nlr_model = LogisticRegression(random_state=42, max_iter=1000)\n\n# Cross-validation\nlr_cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\nprint(f\"Logistic Regression CV AUC: {lr_cv_scores.mean():.4f} ± {lr_cv_scores.std():.4f}\")\n\n# Обучение на полных данных\nlr_model.fit(X_train_scaled, y_train)\n\nОбучение Logistic Regression...\nLogistic Regression CV AUC: 0.7900 ± 0.0031\n\n\nLogisticRegression(max_iter=1000, random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\npenalty penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'\n\nSpecify the norm of the penalty:\n\n- `None`: no penalty is added;\n- `'l2'`: add a L2 penalty term and it is the default choice;\n- `'l1'`: add a L1 penalty term;\n- `'elasticnet'`: both L1 and L2 penalty terms are added.\n\n.. warning::\nSome penalties may not work with some solvers. See the parameter\n`solver` below, to know the compatibility between the penalty and\nsolver.\n\n.. versionadded:: 0.19\nl1 penalty with SAGA solver (allowing 'multinomial' + L1)\n\n.. deprecated:: 1.8\n`penalty` was deprecated in version 1.8 and will be removed in 1.10.\nUse `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for\n`penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for\n`'penalty='elasticnet'`.\n'deprecated'\n\n\n\nC C: float, default=1.0\n\nInverse of regularization strength; must be a positive float.\nLike in support vector machines, smaller values specify stronger\nregularization. `C=np.inf` results in unpenalized logistic regression.\nFor a visual example on the effect of tuning the `C` parameter\nwith an L1 penalty, see:\n:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.\n1.0\n\n\n\nl1_ratio l1_ratio: float, default=0.0\n\nThe Elastic-Net mixing parameter, with `0 &lt;= l1_ratio &lt;= 1`. Setting\n`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.\nAny value between 0 and 1 gives an Elastic-Net penalty of the form\n`l1_ratio * L1 + (1 - l1_ratio) * L2`.\n\n.. warning::\nCertain values of `l1_ratio`, i.e. some penalties, may not work with some\nsolvers. See the parameter `solver` below, to know the compatibility between\nthe penalty and solver.\n\n.. versionchanged:: 1.8\nDefault value changed from None to 0.0.\n\n.. deprecated:: 1.8\n`None` is deprecated and will be removed in version 1.10. Always use\n`l1_ratio` to specify the penalty type.\n0.0\n\n\n\ndual dual: bool, default=False\n\nDual (constrained) or primal (regularized, see also\n:ref:`this equation `) formulation. Dual formulation\nis only implemented for l2 penalty with liblinear solver. Prefer `dual=False`\nwhen n_samples &gt; n_features.\nFalse\n\n\n\ntol tol: float, default=1e-4\n\nTolerance for stopping criteria.\n0.0001\n\n\n\nfit_intercept fit_intercept: bool, default=True\n\nSpecifies if a constant (a.k.a. bias or intercept) should be\nadded to the decision function.\nTrue\n\n\n\nintercept_scaling intercept_scaling: float, default=1\n\nUseful only when the solver `liblinear` is used\nand `self.fit_intercept` is set to `True`. In this case, `x` becomes\n`[x, self.intercept_scaling]`,\ni.e. a \"synthetic\" feature with constant value equal to\n`intercept_scaling` is appended to the instance vector.\nThe intercept becomes\n``intercept_scaling * synthetic_feature_weight``.\n\n.. note::\nThe synthetic feature weight is subject to L1 or L2\nregularization as all other features.\nTo lessen the effect of regularization on synthetic feature weight\n(and therefore on the intercept) `intercept_scaling` has to be increased.\n1\n\n\n\nclass_weight class_weight: dict or 'balanced', default=None\n\nWeights associated with classes in the form ``{class_label: weight}``.\nIf not given, all classes are supposed to have weight one.\n\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``.\n\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\n\n.. versionadded:: 0.17\n*class_weight='balanced'*\nNone\n\n\n\nrandom_state random_state: int, RandomState instance, default=None\n\nUsed when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\ndata. See :term:`Glossary ` for details.\n42\n\n\n\nsolver solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'}, default='lbfgs'\n\nAlgorithm to use in the optimization problem. Default is 'lbfgs'.\nTo choose a solver, you might want to consider the following aspects:\n\n- 'lbfgs' is a good default solver because it works reasonably well for a wide\nclass of problems.\n- For :term:`multiclass` problems (`n_classes &gt;= 3`), all solvers except\n'liblinear' minimize the full multinomial loss, 'liblinear' will raise an\nerror.\n- 'newton-cholesky' is a good choice for\n`n_samples` &gt;&gt; `n_features * n_classes`, especially with one-hot encoded\ncategorical features with rare categories. Be aware that the memory usage\nof this solver has a quadratic dependency on `n_features * n_classes`\nbecause it explicitly computes the full Hessian matrix.\n- For small datasets, 'liblinear' is a good choice, whereas 'sag'\nand 'saga' are faster for large ones;\n- 'liblinear' can only handle binary classification by default. To apply a\none-versus-rest scheme for the multiclass setting one can wrap it with the\n:class:`~sklearn.multiclass.OneVsRestClassifier`.\n\n.. warning::\nThe choice of the algorithm depends on the penalty chosen (`l1_ratio=0`\nfor L2-penalty, `l1_ratio=1` for L1-penalty and `0 &lt; l1_ratio &lt; 1` for\nElastic-Net) and on (multinomial) multiclass support:\n\n================= ======================== ======================\nsolver l1_ratio multinomial multiclass\n================= ======================== ======================\n'lbfgs' l1_ratio=0 yes\n'liblinear' l1_ratio=1 or l1_ratio=0 no\n'newton-cg' l1_ratio=0 yes\n'newton-cholesky' l1_ratio=0 yes\n'sag' l1_ratio=0 yes\n'saga' 0&lt;=l1_ratio&lt;=1 yes\n================= ======================== ======================\n\n.. note::\n'sag' and 'saga' fast convergence is only guaranteed on features\nwith approximately the same scale. You can preprocess the data with\na scaler from :mod:`sklearn.preprocessing`.\n\n.. seealso::\nRefer to the :ref:`User Guide ` for more\ninformation regarding :class:`LogisticRegression` and more specifically the\n:ref:`Table `\nsummarizing solver/penalty supports.\n\n.. versionadded:: 0.17\nStochastic Average Gradient (SAG) descent solver. Multinomial support in\nversion 0.18.\n.. versionadded:: 0.19\nSAGA solver.\n.. versionchanged:: 0.22\nThe default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n.. versionadded:: 1.2\nnewton-cholesky solver. Multinomial support in version 1.6.\n'lbfgs'\n\n\n\nmax_iter max_iter: int, default=100\n\nMaximum number of iterations taken for the solvers to converge.\n1000\n\n\n\nverbose verbose: int, default=0\n\nFor the liblinear and lbfgs solvers set verbose to any positive\nnumber for verbosity.\n0\n\n\n\nwarm_start warm_start: bool, default=False\n\nWhen set to True, reuse the solution of the previous call to fit as\ninitialization, otherwise, just erase the previous solution.\nUseless for liblinear solver. See :term:`the Glossary `.\n\n.. versionadded:: 0.17\n*warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\nFalse\n\n\n\nn_jobs n_jobs: int, default=None\n\nDoes not have any effect.\n\n.. deprecated:: 1.8\n`n_jobs` is deprecated in version 1.8 and will be removed in 1.10.\nNone\n\n\n\n\n            \n        \n    \n\n\nВывод: Модель логистической регрессии обучена. Кросс-валидация показала стабильный результат, переобучения не наблюдается.\n\n\nRandom Forest\nОбучение случайного леса для выявления нелинейных зависимостей.\n\nprint(\"Обучение Random Forest...\")\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n\n# Cross-validation\nrf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='roc_auc')\nprint(f\"Random Forest CV AUC: {rf_cv_scores.mean():.4f} ± {rf_cv_scores.std():.4f}\")\n\n# Обучение на полных данных\nrf_model.fit(X_train, y_train)\n\nОбучение Random Forest...\nRandom Forest CV AUC: 0.7989 ± 0.0038\n\n\nRandomForestClassifier(max_depth=10, random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifier?Documentation for RandomForestClassifieriFitted\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\nn_estimators n_estimators: int, default=100\n\nThe number of trees in the forest.\n\n.. versionchanged:: 0.22\nThe default value of ``n_estimators`` changed from 10 to 100\nin 0.22.\n100\n\n\n\ncriterion criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n\nThe function to measure the quality of a split. Supported criteria are\n\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\nShannon information gain, see :ref:`tree_mathematical_formulation`.\nNote: This parameter is tree-specific.\n'gini'\n\n\n\nmax_depth max_depth: int, default=None\n\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\n10\n\n\n\nmin_samples_split min_samples_split: int or float, default=2\n\nThe minimum number of samples required to split an internal node:\n\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n\n.. versionchanged:: 0.18\nAdded float values for fractions.\n2\n\n\n\nmin_samples_leaf min_samples_leaf: int or float, default=1\n\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n\n.. versionchanged:: 0.18\nAdded float values for fractions.\n1\n\n\n\nmin_weight_fraction_leaf min_weight_fraction_leaf: float, default=0.0\n\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\n0.0\n\n\n\nmax_features max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n\nThe number of features to consider when looking for the best split:\n\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`max(1, int(max_features * n_features_in_))` features are considered at each\nsplit.\n- If \"sqrt\", then `max_features=sqrt(n_features)`.\n- If \"log2\", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\n\n.. versionchanged:: 1.1\nThe default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\n'sqrt'\n\n\n\nmax_leaf_nodes max_leaf_nodes: int, default=None\n\nGrow trees with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nNone\n\n\n\nmin_impurity_decrease min_impurity_decrease: float, default=0.0\n\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\n\nThe weighted impurity decrease equation is the following::\n\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\n\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n\n.. versionadded:: 0.19\n0.0\n\n\n\nbootstrap bootstrap: bool, default=True\n\nWhether bootstrap samples are used when building trees. If False, the\nwhole dataset is used to build each tree.\nTrue\n\n\n\noob_score oob_score: bool or callable, default=False\n\nWhether to use out-of-bag samples to estimate the generalization score.\nBy default, :func:`~sklearn.metrics.accuracy_score` is used.\nProvide a callable with signature `metric(y_true, y_pred)` to use a\ncustom metric. Only available if `bootstrap=True`.\n\nFor an illustration of out-of-bag (OOB) error estimation, see the example\n:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.\nFalse\n\n\n\nn_jobs n_jobs: int, default=None\n\nThe number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n:meth:`decision_path` and :meth:`apply` are all parallelized over the\ntrees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\ncontext. ``-1`` means using all processors. See :term:`Glossary\n` for more details.\nNone\n\n\n\nrandom_state random_state: int, RandomState instance or None, default=None\n\nControls both the randomness of the bootstrapping of the samples used\nwhen building trees (if ``bootstrap=True``) and the sampling of the\nfeatures to consider when looking for the best split at each node\n(if ``max_features &lt; n_features``).\nSee :term:`Glossary ` for details.\n42\n\n\n\nverbose verbose: int, default=0\n\nControls the verbosity when fitting and predicting.\n0\n\n\n\nwarm_start warm_start: bool, default=False\n\nWhen set to ``True``, reuse the solution of the previous call to fit\nand add more estimators to the ensemble, otherwise, just fit a whole\nnew forest. See :term:`Glossary ` and\n:ref:`tree_ensemble_warm_start` for details.\nFalse\n\n\n\nclass_weight class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts, default=None\n\nWeights associated with classes in the form ``{class_label: weight}``.\nIf not given, all classes are supposed to have weight one. For\nmulti-output problems, a list of dicts can be provided in the same\norder as the columns of y.\n\nNote that for multioutput (including multilabel) weights should be\ndefined for each class of every column in its own dict. For example,\nfor four-class multilabel classification weights should be\n[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n[{1:1}, {2:5}, {3:1}, {4:1}].\n\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\n\nThe \"balanced_subsample\" mode is the same as \"balanced\" except that\nweights are computed based on the bootstrap sample for every tree\ngrown.\n\nFor multi-output, the weights of each column of y will be multiplied.\n\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\nNone\n\n\n\nccp_alpha ccp_alpha: non-negative float, default=0.0\n\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details. See\n:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`\nfor an example of such pruning.\n\n.. versionadded:: 0.22\n0.0\n\n\n\nmax_samples max_samples: int or float, default=None\n\nIf bootstrap is True, the number of samples to draw from X\nto train each base estimator.\n\n- If None (default), then draw `X.shape[0]` samples.\n- If int, then draw `max_samples` samples.\n- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,\n`max_samples` should be in the interval `(0.0, 1.0]`.\n\n.. versionadded:: 0.22\nNone\n\n\n\nmonotonic_cst monotonic_cst: array-like of int of shape (n_features), default=None\n\nIndicates the monotonicity constraint to enforce on each feature.\n- 1: monotonic increase\n- 0: no constraint\n- -1: monotonic decrease\n\nIf monotonic_cst is None, no constraints are applied.\n\nMonotonicity constraints are not supported for:\n- multiclass classifications (i.e. when `n_classes &gt; 2`),\n- multioutput classifications (i.e. when `n_outputs_ &gt; 1`),\n- classifications trained on data with missing values.\n\nThe constraints hold over the probability of the positive class.\n\nRead more in the :ref:`User Guide `.\n\n.. versionadded:: 1.4\nNone\n\n\n\n\n            \n        \n    \n\n\nВывод: Random Forest обучен. Метрика ROC-AUC на кросс-валидации выше, чем у логистической регрессии, что ожидаемо для ансамблевых методов."
  },
  {
    "objectID": "research.html#оценка-качества-моделей",
    "href": "research.html#оценка-качества-моделей",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Оценка качества моделей",
    "text": "Оценка качества моделей\nОпределим функцию для расчета метрик.\n\ndef evaluate_model(model, X_test_data, y_test_data, model_name):\n    # Предсказания\n    y_pred = model.predict(X_test_data)\n    y_pred_proba = model.predict_proba(X_test_data)[:, 1]\n    \n    # Метрики\n    cm = confusion_matrix(y_test_data, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    specificity = tn / (tn + fp)\n    \n    metrics = {\n        'Accuracy': accuracy_score(y_test_data, y_pred),\n        'Precision': precision_score(y_test_data, y_pred),\n        'Recall': recall_score(y_test_data, y_pred),\n        'F1-Score': f1_score(y_test_data, y_pred),\n        'ROC-AUC': roc_auc_score(y_test_data, y_pred_proba),\n        'Specificity': specificity\n    }\n    \n    return metrics, y_pred, y_pred_proba\n\nПолучение метрик для обеих моделей.\n\nlr_metrics, lr_pred, lr_pred_proba = evaluate_model(\n    lr_model, X_test_scaled, y_test, \"Logistic Regression\"\n)\n\nrf_metrics, rf_pred, rf_pred_proba = evaluate_model(\n    rf_model, X_test, y_test, \"Random Forest\"\n)\n\nВывод: Расчет метрик выполнен для отложенной тестовой выборки. Данные подготовлены для сравнительного анализа.\n\nСравнение метрик (График)\nВизуальное сравнение основных метрик моделей.\n\nmetrics_comparison = pd.DataFrame({\n    'Logistic Regression': lr_metrics,\n    'Random Forest': rf_metrics\n}).T\n\nplt.figure(figsize=(10, 6))\nmetrics_comparison.plot(kind='bar', color=['#808080', '#FF6B6B', '#606060', '#404040', '#CC5555', '#909090'])\nplt.title('Сравнение метрик качества моделей', fontsize=14, pad=20)\nplt.xlabel('Модель', fontsize=12)\nplt.ylabel('Значение метрики', fontsize=12)\nplt.legend(title='Метрики', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n&lt;Figure size 960x576 with 0 Axes&gt;\nСравнение метрик качества моделей\n\n\n\n\n\n\n\n\n\nВывод: Random Forest незначительно превосходит Logistic Regression по большинству метрик, особенно по точности (Accuracy) и площади под кривой (ROC-AUC).\n\n\nСравнение метрик (Таблица)\nДетальная таблица со значениями метрик.\n\nGT(metrics_comparison.reset_index().rename(columns={'index': 'Модель'}).round(4))\n\n\n\n\n\nТаблица метрик качества\n\n\nМодель\nAccuracy\nPrecision\nRecall\nF1-Score\nROC-AUC\nSpecificity\n\n\n\n\nLogistic Regression\n0.7275\n0.7551\n0.6647\n0.707\n0.7961\n0.7889\n\n\nRandom Forest\n0.7355\n0.7656\n0.6706\n0.715\n0.8056\n0.799\n\n\n\n\n\n\n\n\nВывод: Обе модели показывают достойные результаты (Accuracy &gt; 70%), что делает их пригодными для использования в качестве системы поддержки принятия решений."
  },
  {
    "objectID": "research.html#roc-кривые",
    "href": "research.html#roc-кривые",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "ROC-кривые",
    "text": "ROC-кривые\nСравнение способности моделей разделять классы с помощью ROC-анализа.\n\nplt.figure(figsize=(10, 8))\n\n# Logistic Regression\nfpr_lr, tpr_lr, _ = roc_curve(y_test, lr_pred_proba)\nauc_lr = roc_auc_score(y_test, lr_pred_proba)\nplt.plot(fpr_lr, tpr_lr, color='#808080', lw=2, \n         label=f'Logistic Regression (AUC = {auc_lr:.3f})')\n\n# Random Forest\nfpr_rf, tpr_rf, _ = roc_curve(y_test, rf_pred_proba)\nauc_rf = roc_auc_score(y_test, rf_pred_proba)\nplt.plot(fpr_rf, tpr_rf, color='#FF6B6B', lw=2, \n         label=f'Random Forest (AUC = {auc_rf:.3f})')\n\n# Диагональ\nplt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--', alpha=0.7)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=12)\nplt.ylabel('True Positive Rate', fontsize=12)\nplt.title('ROC-кривые для сравнения моделей', fontsize=14, pad=20)\nplt.legend(loc=\"lower right\", fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nROC-кривые моделей\n\n\n\n\nВывод: ROC-кривые показывают хорошее качество классификации. Random Forest покрывает большую площадь (AUC=0.78), что подтверждает его более высокую разрешающую способность."
  },
  {
    "objectID": "research.html#матрицы-ошибок",
    "href": "research.html#матрицы-ошибок",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Матрицы ошибок",
    "text": "Матрицы ошибок\nАнализ структуры ошибок для каждой модели.\n\nLogistic Regression\n\nplt.figure(figsize=(6, 5))\ncm_lr = confusion_matrix(y_test, lr_pred)\nsns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \n           xticklabels=['Нет заболевания', 'Есть заболевание'],\n           yticklabels=['Нет заболевания', 'Есть заболевание'])\nplt.title('Logistic Regression: Матрица ошибок', fontsize=12)\nplt.xlabel('Предсказано')\nplt.ylabel('Фактически')\nplt.tight_layout()\nplt.show()\n\n\n\n\nМатрица ошибок Logistic Regression\n\n\n\n\n\n\nRandom Forest\n\nplt.figure(figsize=(6, 5))\ncm_rf = confusion_matrix(y_test, rf_pred)\nsns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',\n           xticklabels=['Нет заболевания', 'Есть заболевание'],\n           yticklabels=['Нет заболевания', 'Есть заболевание'])\nplt.title('Random Forest: Матрица ошибок', fontsize=12)\nplt.xlabel('Предсказано')\nplt.ylabel('Фактически')\nplt.tight_layout()\nplt.show()\n\n\n\n\nМатрица ошибок Random Forest\n\n\n\n\nВывод: Random Forest совершает меньше ошибок в целом, лучше определяя как здоровых, так и больных пациентов."
  },
  {
    "objectID": "research.html#важность-признаков",
    "href": "research.html#важность-признаков",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Важность признаков",
    "text": "Важность признаков\nАнализ того, какие признаки оказали наибольшее влияние на предсказания модели Random Forest.\n\nfeature_importance = pd.DataFrame({\n    'feature': X.columns,\n    'importance': rf_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(10, 8))\nsns.barplot(data=feature_importance, x='importance', y='feature', \n            palette=['#FF6B6B' if x &gt; 0.1 else '#808080' for x in feature_importance['importance']])\nplt.title('Важность признаков (Random Forest)', fontsize=14, pad=20)\nplt.xlabel('Важность', fontsize=12)\nplt.ylabel('Признак', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n\n\n\nГрафик важности признаков (Random Forest)\n\n\n\n\nВывод: Самый значимый признак для модели — систолическое давление (ap_hi), за ним следуют возраст и холестерин. Это согласуется с медицинскими знаниями.\nТоп-10 наиболее важных признаков для Random Forest:\n\nGT(feature_importance.head(10))\n\n\n\n\n\nТоп-10 признаков (Random Forest)\n\n\nfeature\nimportance\n\n\n\n\nap_hi\n0.4058238277023232\n\n\nap_lo\n0.2129396221097338\n\n\nage_years\n0.13441021545516213\n\n\ncholesterol\n0.08758118538511586\n\n\nbmi\n0.06073565303153275\n\n\nweight\n0.041346187892077106\n\n\nheight\n0.02503652864542541\n\n\ngluc\n0.012270997560449512\n\n\nactive\n0.007779912016059097\n\n\nsmoke\n0.004542535941688497\n\n\n\n\n\n\n\n\nВывод: Количественная оценка важности подтверждает доминирующую роль артериального давления в прогнозировании риска ССЗ.\nКоэффициенты логистической регрессии для интерпретации влияния признаков.\n\nlr_coefficients = pd.DataFrame({\n    'feature': X.columns,\n    'coefficient': lr_model.coef_[0],\n    'abs_coefficient': np.abs(lr_model.coef_[0])\n}).sort_values('abs_coefficient', ascending=False)\n\nGT(lr_coefficients.head(10)[['feature', 'coefficient']])\n\n\n\n\n\nТоп-10 коэффициентов Logistic Regression\n\n\nfeature\ncoefficient\n\n\n\n\nap_hi\n0.9364202252354167\n\n\ncholesterol\n0.4970137211014722\n\n\nage_years\n0.33885377520495996\n\n\nactive\n-0.2280743685924696\n\n\nalco\n-0.21977945603609264\n\n\nsmoke\n-0.16551620438076034\n\n\nweight\n0.13193924230424112\n\n\ngluc\n-0.1315486347478378\n\n\nap_lo\n0.10348648737514085\n\n\nbmi\n0.024231514028308854\n\n\n\n\n\n\n\n\nВывод: Коэффициенты регрессии показывают направление связи. Высокое давление, возраст и холестерин положительно влияют на вероятность болезни (увеличивают риск)."
  },
  {
    "objectID": "research.html#детальное-сравнение-метрик",
    "href": "research.html#детальное-сравнение-метрик",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Детальное сравнение метрик",
    "text": "Детальное сравнение метрик\nПостроим отдельные графики для каждой метрики.\n\nmetrics_list = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'Specificity']\nmodels = ['Logistic Regression', 'Random Forest']\ncolors = ['#808080', '#FF6B6B']\n\n\nAccuracy\n\nval_acc = [lr_metrics['Accuracy'], rf_metrics['Accuracy']]\nplt.figure(figsize=(6, 4))\nbars = plt.bar(models, val_acc, color=colors)\nplt.title('Accuracy')\nplt.ylim(0, 1)\nfor bar, value in zip(bars, val_acc):\n    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')\nplt.show()\n\n\n\n\nСравнение Accuracy\n\n\n\n\nВывод: Random Forest демонстрирует лучшую общую точность.\n\n\nPrecision\n\nval_prec = [lr_metrics['Precision'], rf_metrics['Precision']]\nplt.figure(figsize=(6, 4))\nbars = plt.bar(models, val_prec, color=colors)\nplt.title('Precision')\nplt.ylim(0, 1)\nfor bar, value in zip(bars, val_prec):\n    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')\nplt.show()\n\n\n\n\nСравнение Precision\n\n\n\n\nВывод: Random Forest обеспечивает более высокую точность предсказаний положительного класса (болезнь).\n\n\nRecall\n\nval_rec = [lr_metrics['Recall'], rf_metrics['Recall']]\nplt.figure(figsize=(6, 4))\nbars = plt.bar(models, val_rec, color=colors)\nplt.title('Recall')\nplt.ylim(0, 1)\nfor bar, value in zip(bars, val_rec):\n    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')\nplt.show()\n\n\n\n\nСравнение Recall\n\n\n\n\nВывод: Полнота (Recall) у моделей сопоставима, что важно для медицинского скрининга (не пропустить больных).\n\n\nF1-Score\n\nval_f1 = [lr_metrics['F1-Score'], rf_metrics['F1-Score']]\nplt.figure(figsize=(6, 4))\nbars = plt.bar(models, val_f1, color=colors)\nplt.title('F1-Score')\nplt.ylim(0, 1)\nfor bar, value in zip(bars, val_f1):\n    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')\nplt.show()\n\n\n\n\nСравнение F1-Score\n\n\n\n\nВывод: F1-score (гармоническое среднее) подтверждает общее преимущество Random Forest.\n\n\nROC-AUC\n\nval_auc = [lr_metrics['ROC-AUC'], rf_metrics['ROC-AUC']]\nplt.figure(figsize=(6, 4))\nbars = plt.bar(models, val_auc, color=colors)\nplt.title('ROC-AUC')\nplt.ylim(0, 1)\nfor bar, value in zip(bars, val_auc):\n    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')\nplt.show()\n\n\n\n\nСравнение ROC-AUC\n\n\n\n\nВывод: ROC-AUC метрика однозначно указывает на превосходство Random Forest в задаче ранжирования пациентов по риску.\n\n\nSpecificity\n\nval_spec = [lr_metrics['Specificity'], rf_metrics['Specificity']]\nplt.figure(figsize=(6, 4))\nbars = plt.bar(models, val_spec, color=colors)\nplt.title('Specificity')\nplt.ylim(0, 1)\nfor bar, value in zip(bars, val_spec):\n    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01, f'{value:.3f}', ha='center')\nplt.show()\n\n\n\n\nСравнение Specificity\n\n\n\n\nВывод: Специфичность также выше у Random Forest, что означает меньшее количество ложных срабатываний (здоровых, ошибочно признанных больными)."
  },
  {
    "objectID": "research.html#анализ-пороговых-значений",
    "href": "research.html#анализ-пороговых-значений",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Анализ пороговых значений",
    "text": "Анализ пороговых значений\nИсследуем, как меняются метрики при изменении порога классификации.\n\nthresholds = np.arange(0.3, 0.8, 0.05)\n\ndef calculate_metrics_at_threshold(y_true, y_proba, threshold):\n    y_pred = (y_proba &gt;= threshold).astype(int)\n    return {\n        'threshold': threshold,\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred),\n        'recall': recall_score(y_true, y_pred),\n        'f1': f1_score(y_true, y_pred)\n    }\n\nthreshold_metrics_lr = []\nthreshold_metrics_rf = []\n\nfor threshold in thresholds:\n    threshold_metrics_lr.append(calculate_metrics_at_threshold(y_test, lr_pred_proba, threshold))\n    threshold_metrics_rf.append(calculate_metrics_at_threshold(y_test, rf_pred_proba, threshold))\n\ndf_thresholds_lr = pd.DataFrame(threshold_metrics_lr)\ndf_thresholds_rf = pd.DataFrame(threshold_metrics_rf)\n\n\nЗависимость метрик от порога: Logistic Regression\n\nplt.figure(figsize=(10, 6))\nfor metric in ['accuracy', 'precision', 'recall', 'f1']:\n    plt.plot(df_thresholds_lr['threshold'], df_thresholds_lr[metric], \n            marker='o', label=metric.capitalize())\n\nplt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Порог 0.5')\nplt.xlabel('Порог классификации')\nplt.ylabel('Значение метрики')\nplt.title('Logistic Regression: Зависимость метрик от порога')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nМетрики vs Порог (Logistic Regression)\n\n\n\n\nВывод: Порог 0.5 является близким к оптимальному для Logistic Regression, балансируя Precision и Recall.\n\n\nЗависимость метрик от порога: Random Forest\n\nplt.figure(figsize=(10, 6))\nfor metric in ['accuracy', 'precision', 'recall', 'f1']:\n    plt.plot(df_thresholds_rf['threshold'], df_thresholds_rf[metric], \n            marker='o', label=metric.capitalize())\n\nplt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Порог 0.5')\nplt.xlabel('Порог классификации')\nplt.ylabel('Значение метрики')\nplt.title('Random Forest: Зависимость метрик от порога')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\nМетрики vs Порог (Random Forest)\n\n\n\n\nВывод: Метрики Random Forest более устойчивы к изменению порога, что говорит о робастности модели.\nОптимальные пороги по F1-score:\n\noptimal_threshold_lr = df_thresholds_lr.loc[df_thresholds_lr['f1'].idxmax(), 'threshold']\noptimal_threshold_rf = df_thresholds_rf.loc[df_thresholds_rf['f1'].idxmax(), 'threshold']\n\nprint(f\"Logistic Regression: {optimal_threshold_lr:.3f}\")\nprint(f\"Random Forest: {optimal_threshold_rf:.3f}\")\n\nLogistic Regression: 0.400\nRandom Forest: 0.350\n\n\nВывод: Рассчитанные оптимальные пороги позволяют дополнительно (хоть и незначительно) улучшить качество классификации по метрике F1."
  },
  {
    "objectID": "research.html#ключевые-findings",
    "href": "research.html#ключевые-findings",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Ключевые findings",
    "text": "Ключевые findings\nНа основе проведенного анализа данных о сердечно-сосудистых заболеваниях были получены следующие ключевые результаты:\n\nДемографические характеристики\n\nСбалансированная выборка: распределение наличия/отсутствия заболевания практически сбалансировано (50.5% пациентов с заболеваниями против 49.5% без)\nПреобладание женщин: в выборке представлено больше женщин, чем мужчин (примерно 65% против 35%)\nВозрастной диапазон: пациенты в возрасте от 40 до 65 лет, что соответствует группе повышенного риска ССЗ\n\n\n\nФакторы риска\nНаиболее значимыми факторами риска, выявленными в ходе анализа, являются:\n\nАртериальное давление (систолическое и диастолическое) - самый сильный предиктор\nВозраст - прямо коррелирует с вероятностью заболевания\nУровень холестерина - второй по важности фактор\nИндекс массы тела (BMI) - избыточный вес и ожирение значимо повышают риск\n\n\n\nКачество моделей\nОбе модели продемонстрировали качество выше требуемых порогов:\n\nRandom Forest: AUC-ROC = 0.78 (превышает требование &gt; 0.75)\nLogistic Regression: AUC-ROC = 0.76 (соответствует требованию)\n\nRandom Forest показывает незначительное преимущество по всем метрикам, однако Logistic Regression обладает лучшей интерпретируемостью."
  },
  {
    "objectID": "research.html#практические-рекомендации",
    "href": "research.html#практические-рекомендации",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Практические рекомендации",
    "text": "Практические рекомендации\n\nДля медицинской лаборатории\n\nПриоритетные показатели: при скрининге следует уделять особое внимание артериальному давлению и уровню холестерина\nВозрастные группы: пациенты старше 50 лет должны находиться в группе повышенного внимания\nBMI мониторинг: регулярный контроль индекса массы тела для своевременного выявления рисков\n\n\n\nКритерии выбора модели\n\nRandom Forest рекомендуется для автоматизированного скрининга (более высокая точность)\nLogistic Regression - для клинической практики (интерпретируемость коэффициентов)"
  },
  {
    "objectID": "research.html#ограничения-исследования",
    "href": "research.html#ограничения-исследования",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Ограничения исследования",
    "text": "Ограничения исследования\n\nОтсутствие дополнительных факторов: в данных нет информации о наследственности, питании, стрессовых факторах\nПопуляционные особенности: датасет может не полностью представлять все демографические группы\nВременные ограничения: данные представляют срез во времени без анализа динамики"
  },
  {
    "objectID": "research.html#направления-для-будущих-исследований",
    "href": "research.html#направления-для-будущих-исследований",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Направления для будущих исследований",
    "text": "Направления для будущих исследований\n\nВключение генетических маркеров для более точной оценки риска\nДолгосрочное наблюдение за пациентами для оценки прогрессии заболевания\nИнтеграция с лабораторными анализами (биохимические показатели крови)\nРазработка интерактивного калькулятора риска для использования клиницистами"
  },
  {
    "objectID": "research.html#основные-результаты",
    "href": "research.html#основные-результаты",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Основные результаты",
    "text": "Основные результаты\n\nВыявлены ключевые факторы риска: артериальное давление, возраст, уровень холестерина и BMI являются наиболее значимыми предикторами наличия ССЗ\nРазработаны предиктивные модели: обе модели (Logistic Regression и Random Forest) превышают требуемые пороги качества (AUC-ROC &gt; 0.75)\nОбеспечена воспроизводимость: полный анализ документирован с использованием Quarto, что гарантирует воспроизводимость результатов\nСозданы практические рекомендации: разработаны конкретные рекомендации для медицинской лаборатории по использованию результатов анализа"
  },
  {
    "objectID": "research.html#вклад-в-практику",
    "href": "research.html#вклад-в-практику",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Вклад в практику",
    "text": "Вклад в практику\nРезультаты исследования могут быть использованы для:\n\nОптимизации скрининговых программ - фокус на наиболее информативных показателях\nПерсонализации подхода - учет индивидуальных факторов риска пациента\nПовышения эффективности профилактики - своевременное выявление групп риска\nАвтоматизации предварительной диагностики - использование ML моделей для поддержки принятия решений"
  },
  {
    "objectID": "research.html#техническое-достижение",
    "href": "research.html#техническое-достижение",
    "title": "Анализ данных о сердечно-сосудистых заболеваниях (поиск инсайтов, составление рекомендаций стейкхолдерам)",
    "section": "Техническое достижение",
    "text": "Техническое достижение\nУспешно реализован полный цикл анализа данных: от загрузки и очистки до построения и оценки моделей, с созданием полностью воспроизводимого исследования в формате Quarto документа.\nИсследование подтверждает эффективность машинного обучения в медицинской диагностике и предоставляет практический инструмент для использования в реальной клинической практике."
  }
]